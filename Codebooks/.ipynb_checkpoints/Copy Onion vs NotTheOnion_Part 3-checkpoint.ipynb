{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88c3aab",
   "metadata": {},
   "source": [
    "# Project 3 Part 3 - Feature Selection and Modelling\n",
    "\n",
    "This notebook will cover:\n",
    "\n",
    "- Selection of the X and y features\n",
    "- Modelling using various model types:\n",
    "    - K-Nearest Neighbours\n",
    "    - Random Forest\n",
    "    - Multinomial Naive Bayes\n",
    "    - Support Vector Machine\n",
    "    - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b96374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, plot_roc_curve, roc_auc_score, recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea27cc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>new_text</th>\n",
       "      <th>newtext_length</th>\n",
       "      <th>newtext_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Woman self-isolates in plane toilet for five h...</td>\n",
       "      <td>1640966006</td>\n",
       "      <td>101</td>\n",
       "      <td>14</td>\n",
       "      <td>woman self isolates in plane toilet for five h...</td>\n",
       "      <td>98</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Humanity's Final Arms Race: UN Fails to Agree ...</td>\n",
       "      <td>1640965471</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>humanity s final arm race un fails to agree on...</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Prince Andrew accuser seeks evidence he could ...</td>\n",
       "      <td>1640963938</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>prince andrew accuser seek evidence he could n...</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Upset over their grievances not being addresse...</td>\n",
       "      <td>1640963308</td>\n",
       "      <td>220</td>\n",
       "      <td>34</td>\n",
       "      <td>upset over their grievance not being addressed...</td>\n",
       "      <td>207</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Thousands of coma patients may be conscious bu...</td>\n",
       "      <td>1640963023</td>\n",
       "      <td>99</td>\n",
       "      <td>14</td>\n",
       "      <td>thousand of coma patient may be conscious but ...</td>\n",
       "      <td>95</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit                                              title  \\\n",
       "0  nottheonion  Woman self-isolates in plane toilet for five h...   \n",
       "1  nottheonion  Humanity's Final Arms Race: UN Fails to Agree ...   \n",
       "2  nottheonion  Prince Andrew accuser seeks evidence he could ...   \n",
       "3  nottheonion  Upset over their grievances not being addresse...   \n",
       "4  nottheonion  Thousands of coma patients may be conscious bu...   \n",
       "\n",
       "   created_utc  title_length  title_word_count  \\\n",
       "0   1640966006           101                14   \n",
       "1   1640965471            67                12   \n",
       "2   1640963938            55                 9   \n",
       "3   1640963308           220                34   \n",
       "4   1640963023            99                14   \n",
       "\n",
       "                                            new_text  newtext_length  \\\n",
       "0  woman self isolates in plane toilet for five h...              98   \n",
       "1  humanity s final arm race un fails to agree on...              63   \n",
       "2  prince andrew accuser seek evidence he could n...              54   \n",
       "3  upset over their grievance not being addressed...             207   \n",
       "4  thousand of coma patient may be conscious but ...              95   \n",
       "\n",
       "   newtext_word_count  \n",
       "0                  16  \n",
       "1                  13  \n",
       "2                   9  \n",
       "3                  33  \n",
       "4                  15  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the dataset\n",
    "onion_or_not = pd.read_csv('../Datasets/onion_or_not.csv')\n",
    "print(onion_or_not.shape)\n",
    "onion_or_not.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21ca9557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>new_text</th>\n",
       "      <th>newtext_length</th>\n",
       "      <th>newtext_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Capital Hospital Islamabad Jobs 2022 for Medic...</td>\n",
       "      <td>1640887476</td>\n",
       "      <td>176</td>\n",
       "      <td>24</td>\n",
       "      <td>capital hospital islamabad job 2022 for medica...</td>\n",
       "      <td>158</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Dad goes to Indian restaurant on Xmas Day &amp;amp...</td>\n",
       "      <td>1640680167</td>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "      <td>dad go to indian restaurant on xmas day amp co...</td>\n",
       "      <td>76</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Santa kicked out of AT&amp;amp;T Stadium after put...</td>\n",
       "      <td>1640672450</td>\n",
       "      <td>74</td>\n",
       "      <td>12</td>\n",
       "      <td>santa kicked out of at amp t stadium after put...</td>\n",
       "      <td>73</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Logan Paul claims people think Jake Paul is th...</td>\n",
       "      <td>1640373611</td>\n",
       "      <td>91</td>\n",
       "      <td>15</td>\n",
       "      <td>logan paul claim people think jake paul is thi...</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Cookies &amp;amp; Cream She’s Eating Herself Out</td>\n",
       "      <td>1640365535</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>cooky amp cream she s eating herself out</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Gamers, We Just Spent 4 Days Trapped In A Roll...</td>\n",
       "      <td>1593025130</td>\n",
       "      <td>172</td>\n",
       "      <td>29</td>\n",
       "      <td>gamers we just spent 4 day trapped in a rolled...</td>\n",
       "      <td>165</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7844</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Bad News, Gamers! ‘Mario &amp;amp; Sonic At The Ol...</td>\n",
       "      <td>1572992691</td>\n",
       "      <td>91</td>\n",
       "      <td>17</td>\n",
       "      <td>bad news gamers mario amp sonic at the olympic...</td>\n",
       "      <td>84</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8290</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Sable &amp;amp; Rosenfeld Launches Ad Campaign Reb...</td>\n",
       "      <td>1565132300</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>sable amp rosenfeld launch ad campaign rebrand...</td>\n",
       "      <td>83</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9161</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Man Entering Fog Of Insanity Asked If This His...</td>\n",
       "      <td>1553781556</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>man entering fog of insanity asked if this his...</td>\n",
       "      <td>78</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>R&amp;amp;B Singer Guesses She’ll Just Keep Moanin...</td>\n",
       "      <td>1547487202</td>\n",
       "      <td>75</td>\n",
       "      <td>13</td>\n",
       "      <td>r amp b singer guess she ll just keep moaning ...</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit                                              title  \\\n",
       "78    nottheonion  Capital Hospital Islamabad Jobs 2022 for Medic...   \n",
       "363   nottheonion  Dad goes to Indian restaurant on Xmas Day &amp...   \n",
       "369   nottheonion  Santa kicked out of AT&amp;T Stadium after put...   \n",
       "606   nottheonion  Logan Paul claims people think Jake Paul is th...   \n",
       "621   nottheonion       Cookies &amp; Cream She’s Eating Herself Out   \n",
       "...           ...                                                ...   \n",
       "6841     TheOnion  Gamers, We Just Spent 4 Days Trapped In A Roll...   \n",
       "7844     TheOnion  Bad News, Gamers! ‘Mario &amp; Sonic At The Ol...   \n",
       "8290     TheOnion  Sable &amp; Rosenfeld Launches Ad Campaign Reb...   \n",
       "9161     TheOnion  Man Entering Fog Of Insanity Asked If This His...   \n",
       "9890     TheOnion  R&amp;B Singer Guesses She’ll Just Keep Moanin...   \n",
       "\n",
       "      created_utc  title_length  title_word_count  \\\n",
       "78     1640887476           176                24   \n",
       "363    1640680167            82                13   \n",
       "369    1640672450            74                12   \n",
       "606    1640373611            91                15   \n",
       "621    1640365535            44                 7   \n",
       "...           ...           ...               ...   \n",
       "6841   1593025130           172                29   \n",
       "7844   1572992691            91                17   \n",
       "8290   1565132300            89                13   \n",
       "9161   1553781556            80                15   \n",
       "9890   1547487202            75                13   \n",
       "\n",
       "                                               new_text  newtext_length  \\\n",
       "78    capital hospital islamabad job 2022 for medica...             158   \n",
       "363   dad go to indian restaurant on xmas day amp co...              76   \n",
       "369   santa kicked out of at amp t stadium after put...              73   \n",
       "606   logan paul claim people think jake paul is thi...              88   \n",
       "621            cooky amp cream she s eating herself out              40   \n",
       "...                                                 ...             ...   \n",
       "6841  gamers we just spent 4 day trapped in a rolled...             165   \n",
       "7844  bad news gamers mario amp sonic at the olympic...              84   \n",
       "8290  sable amp rosenfeld launch ad campaign rebrand...              83   \n",
       "9161  man entering fog of insanity asked if this his...              78   \n",
       "9890  r amp b singer guess she ll just keep moaning ...              73   \n",
       "\n",
       "      newtext_word_count  \n",
       "78                    23  \n",
       "363                   14  \n",
       "369                   14  \n",
       "606                   16  \n",
       "621                    8  \n",
       "...                  ...  \n",
       "6841                  32  \n",
       "7844                  17  \n",
       "8290                  13  \n",
       "9161                  16  \n",
       "9890                  16  \n",
       "\n",
       "[86 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_or_not[onion_or_not.title.str.contains('&amp;')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e44cd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Man Entering Fog Of Insanity Asked If This His First Time At Dave &amp; Buster’s'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_or_not['title'].iloc[9161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50960511",
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_or_not['test'] = onion_or_not.title.apply(lambda x: x.replace(\"&amp; \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73cb6c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Man Entering Fog Of Insanity Asked If This His First Time At Dave Buster’s'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_or_not['test'].iloc[9161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15d2b03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>new_text</th>\n",
       "      <th>newtext_length</th>\n",
       "      <th>newtext_word_count</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Look at The Onion</td>\n",
       "      <td>1639613288</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>look at the onion</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>Look at The Onion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>The Onion Reviews 'Licorice Pizza'</td>\n",
       "      <td>1637771822</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>the onion review licorice pizza</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>The Onion Reviews 'Licorice Pizza'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>The Onion on Not The Onion</td>\n",
       "      <td>1637680099</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>the onion on not the onion</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>The Onion on Not The Onion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>‘The Onion’ Accidentally Sent Our Sex Columnis...</td>\n",
       "      <td>1634006860</td>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "      <td>the onion accidentally sent our sex columnist ...</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>‘The Onion’ Accidentally Sent Our Sex Columnis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>The Onion, FDA Commissioner: I Give up on you ...</td>\n",
       "      <td>1633208339</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>the onion fda commissioner i give up on you pig</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>The Onion, FDA Commissioner: I Give up on you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>The Onion’s Legal Analysts Have Completed Thei...</td>\n",
       "      <td>1555625847</td>\n",
       "      <td>106</td>\n",
       "      <td>18</td>\n",
       "      <td>the onion s legal analyst have completed their...</td>\n",
       "      <td>104</td>\n",
       "      <td>19</td>\n",
       "      <td>The Onion’s Legal Analysts Have Completed Thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9101</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>The Onion Reviews ‘Pet Sematary’</td>\n",
       "      <td>1554393665</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>the onion review pet sematary</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>The Onion Reviews ‘Pet Sematary’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9270</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>The Onion Looks Back At 'Back To The Future'</td>\n",
       "      <td>1552474341</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>the onion look back at back to the future</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>The Onion Looks Back At 'Back To The Future'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>The Onion is dying</td>\n",
       "      <td>1550471127</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>the onion is dying</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>The Onion is dying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9608</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>The Onion’s 2019 Grammy Predictions</td>\n",
       "      <td>1549465441</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>the onion s 2019 grammy prediction</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>The Onion’s 2019 Grammy Predictions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit                                              title  \\\n",
       "1817     TheOnion                                  Look at The Onion   \n",
       "4304     TheOnion                 The Onion Reviews 'Licorice Pizza'   \n",
       "4478  nottheonion                         The Onion on Not The Onion   \n",
       "5307     TheOnion  ‘The Onion’ Accidentally Sent Our Sex Columnis...   \n",
       "5323     TheOnion  The Onion, FDA Commissioner: I Give up on you ...   \n",
       "...           ...                                                ...   \n",
       "8951     TheOnion  The Onion’s Legal Analysts Have Completed Thei...   \n",
       "9101     TheOnion                   The Onion Reviews ‘Pet Sematary’   \n",
       "9270     TheOnion       The Onion Looks Back At 'Back To The Future'   \n",
       "9495     TheOnion                                 The Onion is dying   \n",
       "9608     TheOnion                The Onion’s 2019 Grammy Predictions   \n",
       "\n",
       "      created_utc  title_length  title_word_count  \\\n",
       "1817   1639613288            17                 4   \n",
       "4304   1637771822            34                 5   \n",
       "4478   1637680099            26                 6   \n",
       "5307   1634006860            69                11   \n",
       "5323   1633208339            50                10   \n",
       "...           ...           ...               ...   \n",
       "8951   1555625847           106                18   \n",
       "9101   1554393665            32                 5   \n",
       "9270   1552474341            44                 9   \n",
       "9495   1550471127            18                 4   \n",
       "9608   1549465441            35                 5   \n",
       "\n",
       "                                               new_text  newtext_length  \\\n",
       "1817                                  look at the onion              17   \n",
       "4304                    the onion review licorice pizza              31   \n",
       "4478                         the onion on not the onion              26   \n",
       "5307  the onion accidentally sent our sex columnist ...              67   \n",
       "5323    the onion fda commissioner i give up on you pig              47   \n",
       "...                                                 ...             ...   \n",
       "8951  the onion s legal analyst have completed their...             104   \n",
       "9101                      the onion review pet sematary              29   \n",
       "9270          the onion look back at back to the future              41   \n",
       "9495                                 the onion is dying              18   \n",
       "9608                 the onion s 2019 grammy prediction              34   \n",
       "\n",
       "      newtext_word_count                                               test  \n",
       "1817                   4                                  Look at The Onion  \n",
       "4304                   5                 The Onion Reviews 'Licorice Pizza'  \n",
       "4478                   6                         The Onion on Not The Onion  \n",
       "5307                  11  ‘The Onion’ Accidentally Sent Our Sex Columnis...  \n",
       "5323                  10  The Onion, FDA Commissioner: I Give up on you ...  \n",
       "...                  ...                                                ...  \n",
       "8951                  19  The Onion’s Legal Analysts Have Completed Thei...  \n",
       "9101                   5                   The Onion Reviews ‘Pet Sematary’  \n",
       "9270                   9       The Onion Looks Back At 'Back To The Future'  \n",
       "9495                   4                                 The Onion is dying  \n",
       "9608                   6                The Onion’s 2019 Grammy Predictions  \n",
       "\n",
       "[101 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_or_not[onion_or_not.title.str.contains('The Onion')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d11eaf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>new_text</th>\n",
       "      <th>newtext_length</th>\n",
       "      <th>newtext_word_count</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Best of r/NotTheOnion 2021: Nominations now open!</td>\n",
       "      <td>1640168032</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>best of r nottheonion 2021 nomination now open</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>Best of r/NotTheOnion 2021: Nominations now open!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Tell me this News report doesn’t remind you of...</td>\n",
       "      <td>1602808974</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>tell me this news report doesn t remind you of...</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>Tell me this News report doesn’t remind you of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7224</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>TheOnion.com Has Been Designated As A Pandemic...</td>\n",
       "      <td>1585171615</td>\n",
       "      <td>115</td>\n",
       "      <td>18</td>\n",
       "      <td>theonion com ha been designated a a pandemic s...</td>\n",
       "      <td>113</td>\n",
       "      <td>20</td>\n",
       "      <td>TheOnion.com Has Been Designated As A Pandemic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit                                              title  \\\n",
       "884   nottheonion  Best of r/NotTheOnion 2021: Nominations now open!   \n",
       "6450     TheOnion  Tell me this News report doesn’t remind you of...   \n",
       "7224     TheOnion  TheOnion.com Has Been Designated As A Pandemic...   \n",
       "\n",
       "      created_utc  title_length  title_word_count  \\\n",
       "884    1640168032            49                 7   \n",
       "6450   1602808974            55                10   \n",
       "7224   1585171615           115                18   \n",
       "\n",
       "                                               new_text  newtext_length  \\\n",
       "884      best of r nottheonion 2021 nomination now open              46   \n",
       "6450  tell me this news report doesn t remind you of...              55   \n",
       "7224  theonion com ha been designated a a pandemic s...             113   \n",
       "\n",
       "      newtext_word_count                                               test  \n",
       "884                    8  Best of r/NotTheOnion 2021: Nominations now open!  \n",
       "6450                  11  Tell me this News report doesn’t remind you of...  \n",
       "7224                  20  TheOnion.com Has Been Designated As A Pandemic...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_or_not[onion_or_not.title.str.contains('TheOnion')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffa6a25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>new_text</th>\n",
       "      <th>newtext_length</th>\n",
       "      <th>newtext_word_count</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>/r/nottheonion being renamed to /r/stupidmods</td>\n",
       "      <td>1639232070</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>r nottheonion being renamed to r stupidmods</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>/r/nottheonion being renamed to /r/stupidmods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>“Nottheonion” mods totally aren’t snowflake to...</td>\n",
       "      <td>1637936387</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>nottheonion mod totally aren t snowflake toddl...</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>“Nottheonion” mods totally aren’t snowflake to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4026</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>“Nottheonion” mods are totally not pent up but...</td>\n",
       "      <td>1637936279</td>\n",
       "      <td>93</td>\n",
       "      <td>17</td>\n",
       "      <td>nottheonion mod are totally not pent up butt h...</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>“Nottheonion” mods are totally not pent up but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8933</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Guess If a Headline Is from r/theonion or r/no...</td>\n",
       "      <td>1555881934</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>guess if a headline is from r theonion or r no...</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>Guess If a Headline Is from r/theonion or r/no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit                                              title  \\\n",
       "2284  nottheonion      /r/nottheonion being renamed to /r/stupidmods   \n",
       "4024     TheOnion  “Nottheonion” mods totally aren’t snowflake to...   \n",
       "4026     TheOnion  “Nottheonion” mods are totally not pent up but...   \n",
       "8933     TheOnion  Guess If a Headline Is from r/theonion or r/no...   \n",
       "\n",
       "      created_utc  title_length  title_word_count  \\\n",
       "2284   1639232070            45                 5   \n",
       "4024   1637936387            69                10   \n",
       "4026   1637936279            93                17   \n",
       "8933   1555881934            56                 9   \n",
       "\n",
       "                                               new_text  newtext_length  \\\n",
       "2284        r nottheonion being renamed to r stupidmods              43   \n",
       "4024  nottheonion mod totally aren t snowflake toddl...              64   \n",
       "4026  nottheonion mod are totally not pent up butt h...              84   \n",
       "8933  guess if a headline is from r theonion or r no...              55   \n",
       "\n",
       "      newtext_word_count                                               test  \n",
       "2284                   7      /r/nottheonion being renamed to /r/stupidmods  \n",
       "4024                  11  “Nottheonion” mods totally aren’t snowflake to...  \n",
       "4026                  16  “Nottheonion” mods are totally not pent up but...  \n",
       "8933                  11  Guess If a Headline Is from r/theonion or r/no...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_or_not[onion_or_not.title.str.contains('theonion')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "908cca79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>new_text</th>\n",
       "      <th>newtext_length</th>\n",
       "      <th>newtext_word_count</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>/r/nottheonion being renamed to /r/stupidmods</td>\n",
       "      <td>1639232070</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>r nottheonion being renamed to r stupidmods</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>/r/nottheonion being renamed to /r/stupidmods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8933</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Guess If a Headline Is from r/theonion or r/no...</td>\n",
       "      <td>1555881934</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>guess if a headline is from r theonion or r no...</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>Guess If a Headline Is from r/theonion or r/no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit                                              title  \\\n",
       "2284  nottheonion      /r/nottheonion being renamed to /r/stupidmods   \n",
       "8933     TheOnion  Guess If a Headline Is from r/theonion or r/no...   \n",
       "\n",
       "      created_utc  title_length  title_word_count  \\\n",
       "2284   1639232070            45                 5   \n",
       "8933   1555881934            56                 9   \n",
       "\n",
       "                                               new_text  newtext_length  \\\n",
       "2284        r nottheonion being renamed to r stupidmods              43   \n",
       "8933  guess if a headline is from r theonion or r no...              55   \n",
       "\n",
       "      newtext_word_count                                               test  \n",
       "2284                   7      /r/nottheonion being renamed to /r/stupidmods  \n",
       "8933                  11  Guess If a Headline Is from r/theonion or r/no...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_or_not[onion_or_not.title.str.contains('nottheonion')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a69cf51",
   "metadata": {},
   "source": [
    "## Generating Binary Classifier Column\n",
    "\n",
    "Since we want to create a model that will effectively predict which news is fake, we will use TheOnion as positive, since it is satire and not real news.\n",
    "\n",
    "\n",
    "**1: TheOnion<br>\n",
    "0: nottheonion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "22e4840b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>new_text</th>\n",
       "      <th>newtext_length</th>\n",
       "      <th>newtext_word_count</th>\n",
       "      <th>onion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Woman self-isolates in plane toilet for five h...</td>\n",
       "      <td>1640966006</td>\n",
       "      <td>101</td>\n",
       "      <td>14</td>\n",
       "      <td>woman self isolates in plane toilet for five h...</td>\n",
       "      <td>98</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Humanity's Final Arms Race: UN Fails to Agree ...</td>\n",
       "      <td>1640965471</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>humanity s final arm race un fails to agree on...</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Prince Andrew accuser seeks evidence he could ...</td>\n",
       "      <td>1640963938</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>prince andrew accuser seek evidence he could n...</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Upset over their grievances not being addresse...</td>\n",
       "      <td>1640963308</td>\n",
       "      <td>220</td>\n",
       "      <td>34</td>\n",
       "      <td>upset over their grievance not being addressed...</td>\n",
       "      <td>207</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Thousands of coma patients may be conscious bu...</td>\n",
       "      <td>1640963023</td>\n",
       "      <td>99</td>\n",
       "      <td>14</td>\n",
       "      <td>thousand of coma patient may be conscious but ...</td>\n",
       "      <td>95</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit                                              title  \\\n",
       "0  nottheonion  Woman self-isolates in plane toilet for five h...   \n",
       "1  nottheonion  Humanity's Final Arms Race: UN Fails to Agree ...   \n",
       "2  nottheonion  Prince Andrew accuser seeks evidence he could ...   \n",
       "3  nottheonion  Upset over their grievances not being addresse...   \n",
       "4  nottheonion  Thousands of coma patients may be conscious bu...   \n",
       "\n",
       "   created_utc  title_length  title_word_count  \\\n",
       "0   1640966006           101                14   \n",
       "1   1640965471            67                12   \n",
       "2   1640963938            55                 9   \n",
       "3   1640963308           220                34   \n",
       "4   1640963023            99                14   \n",
       "\n",
       "                                            new_text  newtext_length  \\\n",
       "0  woman self isolates in plane toilet for five h...              98   \n",
       "1  humanity s final arm race un fails to agree on...              63   \n",
       "2  prince andrew accuser seek evidence he could n...              54   \n",
       "3  upset over their grievance not being addressed...             207   \n",
       "4  thousand of coma patient may be conscious but ...              95   \n",
       "\n",
       "   newtext_word_count  onion  \n",
       "0                  16      0  \n",
       "1                  13      0  \n",
       "2                   9      0  \n",
       "3                  33      0  \n",
       "4                  15      0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create column for 1s and 0s for subreddit\n",
    "# TheOnion : 1, notthe onion : 0\n",
    "onion_or_not['onion'] = [1 if value == 'TheOnion' else 0 for value in onion_or_not.subreddit.values]\n",
    "onion_or_not.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8410dd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5000\n",
      "1    5000\n",
      "Name: onion, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: onion, dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as stated in the previous notebook, the classes are perfectly balanced\n",
    "print(onion_or_not.onion.value_counts(normalize=False))\n",
    "onion_or_not.onion.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603ff379",
   "metadata": {},
   "source": [
    "### The X and y features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ad9021",
   "metadata": {},
   "source": [
    "We will use the `new_text` to predict whether a title is from the onion or not. The `new_text` is the tokenized and lemmatized version of the original `title` text.<br>\n",
    "Hence, our X will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3f7cad45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    woman self isolates in plane toilet for five h...\n",
       "1    humanity s final arm race un fails to agree on...\n",
       "2    prince andrew accuser seek evidence he could n...\n",
       "3    upset over their grievance not being addressed...\n",
       "4    thousand of coma patient may be conscious but ...\n",
       "Name: new_text, dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = onion_or_not.new_text\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd18f36c",
   "metadata": {},
   "source": [
    "Our y will simply be the `onion` column of 1s and 0s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7bd68d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: onion, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = onion_or_not.onion\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae693b0",
   "metadata": {},
   "source": [
    "### Train, Test and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "050b017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test and split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f02cdff",
   "metadata": {},
   "source": [
    "## Important metrics for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa9ec57",
   "metadata": {},
   "source": [
    "### Which is worse, FALSE POSITIVES or FALSE NEGATIVES?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936e1b89",
   "metadata": {},
   "source": [
    "**False Positive - News that is real, but wrongly classified as fake.<br>\n",
    "False Negative - News that is fake, but wrongly classified as real.**<br>\n",
    "\n",
    "False positives are important, as the implications of classifying real news as fake can be serious. For example, real news about vaccines being classified as fake can have a serious impact on the healthcare system and vaccination efforts of a nation.\n",
    "\n",
    "That said, false negatives hold equal importance as well. For example, classifying a fake news about a terrorist attack as real will cause undue panic and anxiety, which will cause unecessary stress the security and defence personnel.\n",
    "\n",
    "Since avoiding both false positives and false negatives are equally important for our problem, we need a trade-off between precision and recall. We will thus **use the f1 score as the main metric**. The f1 score is defined as the harmonic mean of precision and recall.<sup>1</sup><br>\n",
    "Nevertheless, we will still look at other metrics, namely:\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1d015",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8e5f8",
   "metadata": {},
   "source": [
    "We will model the data using the following models:\n",
    "- K-Nearest Neighbours\n",
    "- Random Forest\n",
    "- Multinomial Naive Bayes\n",
    "- Support Vector Machine\n",
    "- Logistic Regression\n",
    "\n",
    "The model with the best metric will be chosen as our primary model, on which we will perform further study and draw reccomendations and conclusions from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd654d19",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "It is tempting to just use accuracy score of 0.5 as the baseline. This however, would be pointless as it is overly basic, and the dataset is deliberately balanced in the first place. We will thus use k-Nearest Neighbours as the baseline model as it is a proper model, yet basic enough for a baseline evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b8ec5de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create KNN pipeline\n",
    "# no default CountVectorizer and KNN will be used as it is a baseline\n",
    "pipe_knn_base = Pipeline([\n",
    "    ('cvec', CountVectorizer()), # instantiate CountVectorizer\n",
    "    ('knn', KNeighborsClassifier()) # Instantiate KNN\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1ad2cbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer()), ('knn', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the train data\n",
    "pipe_knn_base.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e3b937a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline train accuracy score: 0.7388\n",
      "Baseline test accuracy score: 0.6076\n"
     ]
    }
   ],
   "source": [
    "# get the score on the train and test sets\n",
    "print(f'Baseline train accuracy score: {pipe_knn_base.score(X_train, y_train)}')\n",
    "print(f'Baseline test accuracy score: {pipe_knn_base.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d509967d",
   "metadata": {},
   "source": [
    "The model is overfit, as can be seen by the difference between the train and test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4b3042c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test RECALL: 0.6392\n",
      "Baseline test PRECISION: 0.6012039127163281\n",
      "Baseline test f1 SCORE: 0.6196200077549439\n"
     ]
    }
   ],
   "source": [
    "# what are the other test set metrics for baseline KNN model?\n",
    "print(f'Baseline test RECALL: {recall_score(y_test, pipe_knn_base.predict(X_test))}')\n",
    "print(f'Baseline test PRECISION: {precision_score(y_test, pipe_knn_base.predict(X_test))}')\n",
    "print(f'Baseline test f1 SCORE: {f1_score(y_test, pipe_knn_base.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea3584",
   "metadata": {},
   "source": [
    "**Summary of the test scores for the baseline KNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6d0b6572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric        Score\n",
      "---------  --------\n",
      "Accuracy   0.6076\n",
      "Recall     0.6392\n",
      "Precision  0.601204\n",
      "f1 Score   0.61962\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Metric', 'Score'],\n",
    "                ['Accuracy', pipe_knn_base.score(X_test, y_test)],\n",
    "               ['Recall', recall_score(y_test, pipe_knn_base.predict(X_test))],\n",
    "               ['Precision', precision_score(y_test, pipe_knn_base.predict(X_test))],\n",
    "               ['f1 Score', f1_score(y_test, pipe_knn_base.predict(X_test))]],\n",
    "               headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47314ce4",
   "metadata": {},
   "source": [
    "Scores for the metrics are overall not that good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2123d",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors (KNN) Model Hyperparameter Tuning\n",
    "Since the baseline performed rather poorly, we will tune the hyperparameters of the the KNN model to see if the score can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6a3df774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create KNN pipeline\n",
    "pipe_knn = Pipeline([\n",
    "    ('cvec', CountVectorizer()), # instantiate CountVectorizer\n",
    "    ('knn', KNeighborsClassifier()) # Instantiate KNN\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fe42baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer and KNN parameters\n",
    "pipe_knn_params = {\n",
    "    'cvec__max_features': [None, 1000, 2000, 3000],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__max_df': [.8, .85],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'knn__n_neighbors': [1, 3, 5, 7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fe3bce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch for KNN\n",
    "gs_knn = GridSearchCV(pipe_knn,\n",
    "                     param_grid=pipe_knn_params,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f3eaa1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.8, 0.85],\n",
       "                         'cvec__max_features': [None, 1000, 2000, 3000],\n",
       "                         'cvec__min_df': [1, 2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'knn__n_neighbors': [1, 3, 5, 7]})"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the training data\n",
    "gs_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2f1d760b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.8, 'cvec__max_features': None, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': 'english', 'knn__n_neighbors': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6612"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where are the best parameters in KNN model\n",
    "print(gs_knn.best_params_)\n",
    "\n",
    "# best score for KNN model\n",
    "gs_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e5f165bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN train accuracy score: 0.9997333333333334\n",
      "KNN test accuracy score: 0.6824\n"
     ]
    }
   ],
   "source": [
    "# what are the KNN accuracy scores?\n",
    "print(f'KNN train accuracy score: {gs_knn.score(X_train, y_train)}')\n",
    "print(f'KNN test accuracy score: {gs_knn.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c21ce7",
   "metadata": {},
   "source": [
    "A number of observations can be seen by comparing the KNN model with hyperparameter tuning with the baseline.\n",
    "- Removal of english stop words helps to improve the test and train score\n",
    "- Usage of uni-grams help improve the test and train score\n",
    "- The nearest neighbours that worked best for this model is **1**.\n",
    "- Although scores have improved, overfitting is still present, and severe.\n",
    "\n",
    "This will help with adjusting the parameters for the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c3839e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN test RECALL: 0.9008\n",
      "KNN test PRECISION: 0.6269487750556793\n",
      "KNN test f1 SCORE: 0.7393302692055155\n"
     ]
    }
   ],
   "source": [
    "# what are the test scores of the other metrics for KNN model\n",
    "print(f'KNN test RECALL: {recall_score(y_test, gs_knn.predict(X_test))}')\n",
    "print(f'KNN test PRECISION: {precision_score(y_test, gs_knn.predict(X_test))}')\n",
    "print(f'KNN test f1 SCORE: {f1_score(y_test, gs_knn.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78981d08",
   "metadata": {},
   "source": [
    "There is significant improvement for Recall and f1 Scores, and a small improvement for Precision.<br>\n",
    "High recall shows that we have very few false negatives.<br>\n",
    "Low precision is indicative of high number of false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f568129c",
   "metadata": {},
   "source": [
    "**Summary of the test scores for the KNN Model with hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc406665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric        Score\n",
      "---------  --------\n",
      "Accuracy   0.6824\n",
      "Recall     0.9008\n",
      "Precision  0.626949\n",
      "f1 Score   0.73933\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Metric', 'Score'],\n",
    "                ['Accuracy', gs_knn.score(X_test, y_test)],\n",
    "               ['Recall', recall_score(y_test, gs_knn.predict(X_test))],\n",
    "               ['Precision', precision_score(y_test, gs_knn.predict(X_test))],\n",
    "               ['f1 Score', f1_score(y_test, gs_knn.predict(X_test))]],\n",
    "               headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d3d3ef",
   "metadata": {},
   "source": [
    "### Random Forest with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f033157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for RandomForest\n",
    "pipe_rf = Pipeline([\n",
    "    ('cvec', CountVectorizer()), # instantiate CountVectorizer\n",
    "    ('rf', RandomForestClassifier()) # instantiate RandomForest\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13149622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer and RandomForest parameters\n",
    "pipe_rf_params = {\n",
    "    'cvec__max_features': [None, 1000, 2000, 3000],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__max_df': [.8, .85],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'rf__n_estimators': [100, 200, 300],\n",
    "    'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
    "    'rf__random_state': [42],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22e0d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch for RandomForest\n",
    "gs_rf = GridSearchCV(pipe_rf,\n",
    "                     param_grid=pipe_rf_params,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cb5b227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.8, 0.85],\n",
       "                         'cvec__max_features': [None, 1000, 2000, 3000],\n",
       "                         'cvec__min_df': [1, 2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
       "                         'rf__n_estimators': [100, 200, 300],\n",
       "                         'rf__random_state': [42]})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the training data to the RandomForest model\n",
    "gs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "719c15b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.8, 'cvec__max_features': None, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': None, 'rf__max_depth': None, 'rf__n_estimators': 200, 'rf__random_state': 42}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7797333333333334"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where are the best parameters in RandomForest model\n",
    "print(gs_rf.best_params_)\n",
    "\n",
    "# best score for RandForest model\n",
    "gs_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "529158b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest train accuracy score: 1.0\n",
      "RandomForest test accuracy score: 0.7932\n"
     ]
    }
   ],
   "source": [
    "# what are the RandomForest accuracy scores?\n",
    "print(f'RandomForest train accuracy score: {gs_rf.score(X_train, y_train)}')\n",
    "print(f'RandomForest test accuracy score: {gs_rf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a6e711",
   "metadata": {},
   "source": [
    "Some interesting observations for RandomForest:\n",
    "- Although the accuracy is high with test accuracy outperforming the KNN train accuracy, the model is still overfit.\n",
    "- Uni-grams, work best for this model.\n",
    "- No stop words were removed, which was the best for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "703dc826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest test RECALL: 0.8624\n",
      "RandomForest test PRECISION: 0.7575544624033732\n",
      "RandomForest test f1 SCORE: 0.8065843621399178\n"
     ]
    }
   ],
   "source": [
    "# what are the test scores of the other metrics for RandomForest model\n",
    "print(f'RandomForest test RECALL: {recall_score(y_test, gs_rf.predict(X_test))}')\n",
    "print(f'RandomForest test PRECISION: {precision_score(y_test, gs_rf.predict(X_test))}')\n",
    "print(f'RandomForest test f1 SCORE: {f1_score(y_test, gs_rf.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff216d2",
   "metadata": {},
   "source": [
    "Of all the scores, Precision was the lowest, similar to that of KNN, indicating that RandomForest also predicted a proportionally higher number of false positives.\n",
    "\n",
    "\n",
    "**Summary of the test scores for the RandomForest Model with hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "063630ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric        Score\n",
      "---------  --------\n",
      "Accuracy   0.7932\n",
      "Recall     0.8624\n",
      "Precision  0.757554\n",
      "f1 Score   0.806584\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Metric', 'Score'],\n",
    "                ['Accuracy', gs_rf.score(X_test, y_test)],\n",
    "               ['Recall', recall_score(y_test, gs_rf.predict(X_test))],\n",
    "               ['Precision', precision_score(y_test, gs_rf.predict(X_test))],\n",
    "               ['f1 Score', f1_score(y_test, gs_rf.predict(X_test))]],\n",
    "               headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a88dde",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes (MNB) with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "872574c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline for MNB\n",
    "pipe_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()), # instantiate CountVectorizer\n",
    "    ('nb', MultinomialNB()) # instantiate MNB\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d5356611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer and MNB parameters\n",
    "pipe_nb_params = {\n",
    "    'cvec__max_features': [None, 1000, 2000, 3000],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__max_df': [.8, .85],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'nb__alpha': np.linspace(0.5, 1.8, 8),\n",
    "    'nb__fit_prior': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8add2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV for MNB\n",
    "gs_nb = GridSearchCV(pipe_nb, \n",
    "                     param_grid=pipe_nb_params,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f6aebea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.8, 0.85],\n",
       "                         'cvec__max_features': [None, 1000, 2000, 3000],\n",
       "                         'cvec__min_df': [1, 2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'nb__alpha': array([0.5       , 0.68571429, 0.87142857, 1.05714286, 1.24285714,\n",
       "       1.42857143, 1.61428571, 1.8       ]),\n",
       "                         'nb__fit_prior': [True, False]})"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the training data to the MNB model\n",
    "gs_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e3856178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.8, 'cvec__max_features': None, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': None, 'nb__alpha': 0.8714285714285714, 'nb__fit_prior': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8172"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where are the best parameters in MNB model\n",
    "print(gs_nb.best_params_)\n",
    "\n",
    "# best score for MNB model\n",
    "gs_nb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3c4097ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB train accuracy score: 0.9972\n",
      "MNB test accuracy score: 0.842\n"
     ]
    }
   ],
   "source": [
    "# what are the MNB accuracy scores?\n",
    "print(f'MNB train accuracy score: {gs_nb.score(X_train, y_train)}')\n",
    "print(f'MNB test accuracy score: {gs_nb.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b665091",
   "metadata": {},
   "source": [
    "Interesting observations from MNB:\n",
    "- Uni-grams to Tri-grams range worked the best\n",
    "- No stop word removal worked best for the model\n",
    "- alpha value of **0.8714**\n",
    "- Model is strong predictor with a relatively high test score, but still overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9694ce25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB test RECALL: 0.8512\n",
      "MNB test PRECISION: 0.835820895522388\n",
      "MNB test f1 SCORE: 0.8434403487911216\n"
     ]
    }
   ],
   "source": [
    "# what are the test scores of the other metrics for MNB model\n",
    "print(f'MNB test RECALL: {recall_score(y_test, gs_nb.predict(X_test))}')\n",
    "print(f'MNB test PRECISION: {precision_score(y_test, gs_nb.predict(X_test))}')\n",
    "print(f'MNB test f1 SCORE: {f1_score(y_test, gs_nb.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e771166",
   "metadata": {},
   "source": [
    "All scores apprear to not differ that much, with Precision being the lowest and Recall being the highest.<br>\n",
    "F1 score outperforms that of baseline, and KNN and RandomForest with hyperparameter tuning.\n",
    "\n",
    "**Summary of the test scores for the RandomForest Model with hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d60fe935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric        Score\n",
      "---------  --------\n",
      "Accuracy   0.842\n",
      "Recall     0.8512\n",
      "Precision  0.835821\n",
      "f1 Score   0.84344\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Metric', 'Score'],\n",
    "                ['Accuracy', gs_nb.score(X_test, y_test)],\n",
    "               ['Recall', recall_score(y_test, gs_nbb.predict(X_test))],\n",
    "               ['Precision', precision_score(y_test, gs_nb.predict(X_test))],\n",
    "               ['f1 Score', f1_score(y_test, gs_nb.predict(X_test))]],\n",
    "               headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa0732",
   "metadata": {},
   "source": [
    "### Logistic Regression with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a91d51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline for LogisticRegression\n",
    "pipe_log = Pipeline([\n",
    "    ('cvec', CountVectorizer()), # instantiate CountVectorizer\n",
    "    ('log', LogisticRegression()) # instantiate LogisticRegression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6742951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_log_params = {\n",
    "    'cvec__max_features': [None, 1000, 2000, 3000],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__max_df': [.8, .85],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'log__penalty': ['l1', 'l2'],\n",
    "    'log__max_iter': [100, 300, 500],\n",
    "    'log__random_state': [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0ca2b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV for Logistic Regression\n",
    "gs_log = GridSearchCV(pipe_log, \n",
    "                     param_grid=pipe_log_params,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6bd8bf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.7972            nan 0.7972            nan 0.7972\n",
      "        nan 0.7772            nan 0.7772            nan 0.7772\n",
      "        nan 0.80186667        nan 0.80186667        nan 0.80186667\n",
      "        nan 0.7908            nan 0.7908            nan 0.7908\n",
      "        nan 0.802             nan 0.802             nan 0.802\n",
      "        nan 0.78773333        nan 0.78773333        nan 0.78773333\n",
      "        nan 0.7944            nan 0.7944            nan 0.7944\n",
      "        nan 0.77333333        nan 0.77333333        nan 0.77333333\n",
      "        nan 0.8008            nan 0.8008            nan 0.8008\n",
      "        nan 0.78186667        nan 0.78186667        nan 0.78186667\n",
      "        nan 0.7992            nan 0.7992            nan 0.7992\n",
      "        nan 0.78026667        nan 0.78026667        nan 0.78026667\n",
      "        nan 0.78893333        nan 0.78893333        nan 0.78893333\n",
      "        nan 0.768             nan 0.768             nan 0.768\n",
      "        nan 0.79293333        nan 0.79293333        nan 0.79293333\n",
      "        nan 0.77253333        nan 0.77253333        nan 0.77253333\n",
      "        nan 0.7928            nan 0.7928            nan 0.7928\n",
      "        nan 0.77266667        nan 0.77266667        nan 0.77266667\n",
      "        nan 0.76186667        nan 0.76186667        nan 0.76186667\n",
      "        nan 0.73346667        nan 0.73346667        nan 0.73346667\n",
      "        nan 0.7592            nan 0.7592            nan 0.7592\n",
      "        nan 0.73186667        nan 0.73186667        nan 0.73186667\n",
      "        nan 0.75773333        nan 0.75773333        nan 0.75773333\n",
      "        nan 0.73013333        nan 0.73013333        nan 0.73013333\n",
      "        nan 0.7624            nan 0.7624            nan 0.7624\n",
      "        nan 0.73653333        nan 0.73653333        nan 0.73653333\n",
      "        nan 0.7588            nan 0.7588            nan 0.7588\n",
      "        nan 0.73106667        nan 0.73106667        nan 0.73106667\n",
      "        nan 0.75906667        nan 0.75906667        nan 0.75906667\n",
      "        nan 0.73093333        nan 0.73093333        nan 0.73093333\n",
      "        nan 0.7624            nan 0.7624            nan 0.7624\n",
      "        nan 0.73466667        nan 0.73466667        nan 0.73466667\n",
      "        nan 0.75986667        nan 0.75986667        nan 0.75986667\n",
      "        nan 0.7288            nan 0.7288            nan 0.7288\n",
      "        nan 0.75786667        nan 0.75786667        nan 0.75786667\n",
      "        nan 0.73053333        nan 0.73053333        nan 0.73053333\n",
      "        nan 0.77346667        nan 0.77346667        nan 0.77346667\n",
      "        nan 0.75706667        nan 0.75706667        nan 0.75706667\n",
      "        nan 0.7756            nan 0.7756            nan 0.7756\n",
      "        nan 0.75653333        nan 0.75653333        nan 0.75653333\n",
      "        nan 0.77466667        nan 0.77466667        nan 0.77466667\n",
      "        nan 0.7556            nan 0.7556            nan 0.7556\n",
      "        nan 0.77493333        nan 0.77493333        nan 0.77493333\n",
      "        nan 0.75506667        nan 0.75506667        nan 0.75506667\n",
      "        nan 0.774             nan 0.774             nan 0.774\n",
      "        nan 0.7568            nan 0.7568            nan 0.7568\n",
      "        nan 0.776             nan 0.776             nan 0.776\n",
      "        nan 0.75586667        nan 0.75586667        nan 0.75586667\n",
      "        nan 0.7752            nan 0.7752            nan 0.7752\n",
      "        nan 0.756             nan 0.756             nan 0.756\n",
      "        nan 0.77733333        nan 0.77733333        nan 0.77733333\n",
      "        nan 0.756             nan 0.756             nan 0.756\n",
      "        nan 0.77546667        nan 0.77546667        nan 0.77546667\n",
      "        nan 0.75586667        nan 0.75586667        nan 0.75586667\n",
      "        nan 0.7852            nan 0.7852            nan 0.7852\n",
      "        nan 0.76306667        nan 0.76306667        nan 0.76306667\n",
      "        nan 0.7788            nan 0.7788            nan 0.7788\n",
      "        nan 0.7624            nan 0.7624            nan 0.7624\n",
      "        nan 0.78013333        nan 0.78013333        nan 0.78013333\n",
      "        nan 0.76093333        nan 0.76093333        nan 0.76093333\n",
      "        nan 0.784             nan 0.784             nan 0.784\n",
      "        nan 0.76213333        nan 0.76213333        nan 0.76213333\n",
      "        nan 0.77986667        nan 0.77986667        nan 0.77986667\n",
      "        nan 0.764             nan 0.764             nan 0.764\n",
      "        nan 0.78053333        nan 0.78053333        nan 0.78053333\n",
      "        nan 0.7616            nan 0.7616            nan 0.7616\n",
      "        nan 0.78493333        nan 0.78493333        nan 0.78493333\n",
      "        nan 0.76253333        nan 0.76253333        nan 0.76253333\n",
      "        nan 0.7792            nan 0.7792            nan 0.7792\n",
      "        nan 0.76186667        nan 0.76186667        nan 0.76186667\n",
      "        nan 0.77986667        nan 0.77986667        nan 0.77986667\n",
      "        nan 0.76346667        nan 0.76346667        nan 0.76346667\n",
      "        nan 0.7972            nan 0.7972            nan 0.7972\n",
      "        nan 0.7772            nan 0.7772            nan 0.7772\n",
      "        nan 0.80186667        nan 0.80186667        nan 0.80186667\n",
      "        nan 0.7908            nan 0.7908            nan 0.7908\n",
      "        nan 0.802             nan 0.802             nan 0.802\n",
      "        nan 0.78773333        nan 0.78773333        nan 0.78773333\n",
      "        nan 0.7944            nan 0.7944            nan 0.7944\n",
      "        nan 0.77333333        nan 0.77333333        nan 0.77333333\n",
      "        nan 0.8008            nan 0.8008            nan 0.8008\n",
      "        nan 0.78186667        nan 0.78186667        nan 0.78186667\n",
      "        nan 0.7992            nan 0.7992            nan 0.7992\n",
      "        nan 0.78026667        nan 0.78026667        nan 0.78026667\n",
      "        nan 0.78893333        nan 0.78893333        nan 0.78893333\n",
      "        nan 0.768             nan 0.768             nan 0.768\n",
      "        nan 0.79293333        nan 0.79293333        nan 0.79293333\n",
      "        nan 0.77253333        nan 0.77253333        nan 0.77253333\n",
      "        nan 0.7928            nan 0.7928            nan 0.7928\n",
      "        nan 0.77266667        nan 0.77266667        nan 0.77266667\n",
      "        nan 0.76186667        nan 0.76186667        nan 0.76186667\n",
      "        nan 0.73346667        nan 0.73346667        nan 0.73346667\n",
      "        nan 0.7592            nan 0.7592            nan 0.7592\n",
      "        nan 0.73186667        nan 0.73186667        nan 0.73186667\n",
      "        nan 0.75773333        nan 0.75773333        nan 0.75773333\n",
      "        nan 0.73013333        nan 0.73013333        nan 0.73013333\n",
      "        nan 0.7624            nan 0.7624            nan 0.7624\n",
      "        nan 0.73653333        nan 0.73653333        nan 0.73653333\n",
      "        nan 0.7588            nan 0.7588            nan 0.7588\n",
      "        nan 0.73106667        nan 0.73106667        nan 0.73106667\n",
      "        nan 0.75906667        nan 0.75906667        nan 0.75906667\n",
      "        nan 0.73093333        nan 0.73093333        nan 0.73093333\n",
      "        nan 0.7624            nan 0.7624            nan 0.7624\n",
      "        nan 0.73466667        nan 0.73466667        nan 0.73466667\n",
      "        nan 0.75986667        nan 0.75986667        nan 0.75986667\n",
      "        nan 0.7288            nan 0.7288            nan 0.7288\n",
      "        nan 0.75786667        nan 0.75786667        nan 0.75786667\n",
      "        nan 0.73053333        nan 0.73053333        nan 0.73053333\n",
      "        nan 0.77346667        nan 0.77346667        nan 0.77346667\n",
      "        nan 0.75706667        nan 0.75706667        nan 0.75706667\n",
      "        nan 0.7756            nan 0.7756            nan 0.7756\n",
      "        nan 0.75653333        nan 0.75653333        nan 0.75653333\n",
      "        nan 0.77466667        nan 0.77466667        nan 0.77466667\n",
      "        nan 0.7556            nan 0.7556            nan 0.7556\n",
      "        nan 0.77493333        nan 0.77493333        nan 0.77493333\n",
      "        nan 0.75506667        nan 0.75506667        nan 0.75506667\n",
      "        nan 0.774             nan 0.774             nan 0.774\n",
      "        nan 0.7568            nan 0.7568            nan 0.7568\n",
      "        nan 0.776             nan 0.776             nan 0.776\n",
      "        nan 0.75586667        nan 0.75586667        nan 0.75586667\n",
      "        nan 0.7752            nan 0.7752            nan 0.7752\n",
      "        nan 0.756             nan 0.756             nan 0.756\n",
      "        nan 0.77733333        nan 0.77733333        nan 0.77733333\n",
      "        nan 0.756             nan 0.756             nan 0.756\n",
      "        nan 0.77546667        nan 0.77546667        nan 0.77546667\n",
      "        nan 0.75586667        nan 0.75586667        nan 0.75586667\n",
      "        nan 0.7852            nan 0.7852            nan 0.7852\n",
      "        nan 0.76306667        nan 0.76306667        nan 0.76306667\n",
      "        nan 0.7788            nan 0.7788            nan 0.7788\n",
      "        nan 0.7624            nan 0.7624            nan 0.7624\n",
      "        nan 0.78013333        nan 0.78013333        nan 0.78013333\n",
      "        nan 0.76093333        nan 0.76093333        nan 0.76093333\n",
      "        nan 0.784             nan 0.784             nan 0.784\n",
      "        nan 0.76213333        nan 0.76213333        nan 0.76213333\n",
      "        nan 0.77986667        nan 0.77986667        nan 0.77986667\n",
      "        nan 0.764             nan 0.764             nan 0.764\n",
      "        nan 0.78053333        nan 0.78053333        nan 0.78053333\n",
      "        nan 0.7616            nan 0.7616            nan 0.7616\n",
      "        nan 0.78493333        nan 0.78493333        nan 0.78493333\n",
      "        nan 0.76253333        nan 0.76253333        nan 0.76253333\n",
      "        nan 0.7792            nan 0.7792            nan 0.7792\n",
      "        nan 0.76186667        nan 0.76186667        nan 0.76186667\n",
      "        nan 0.77986667        nan 0.77986667        nan 0.77986667\n",
      "        nan 0.76346667        nan 0.76346667        nan 0.76346667]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('log', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.8, 0.85],\n",
       "                         'cvec__max_features': [None, 1000, 2000, 3000],\n",
       "                         'cvec__min_df': [1, 2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'log__max_iter': [100, 300, 500],\n",
       "                         'log__penalty': ['l1', 'l2'],\n",
       "                         'log__random_state': [42]})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the training data to the LogisticRegression model\n",
    "gs_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fbef8249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.8, 'cvec__max_features': None, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': None, 'log__max_iter': 100, 'log__penalty': 'l2', 'log__random_state': 42}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8019999999999999"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where are the best parameters in LogisticRegression model\n",
    "print(gs_log.best_params_)\n",
    "\n",
    "# best score for LogisticRegression model\n",
    "gs_log.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ef76092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression train accuracy score: 1.0\n",
      "LogisticRegression test accuracy score: 0.8208\n"
     ]
    }
   ],
   "source": [
    "# what are the LogisticRegression accuracy scores?\n",
    "print(f'LogisticRegression train accuracy score: {gs_log.score(X_train, y_train)}')\n",
    "print(f'LogisticRegression test accuracy score: {gs_log.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18af8064",
   "metadata": {},
   "source": [
    "Interesting observations with Logistic Regression:\n",
    "- Uni-grams to Tri-grams worked the best for this model\n",
    "- No stop words were removed, which worked the best for this model\n",
    "- l2 penalty, ie Ridge Regression worked best for the model\n",
    "- Model is also overfit, with train score being 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fe38a4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression test RECALL: 0.8392\n",
      "LogisticRegression test PRECISION: 0.8094135802469136\n",
      "LogisticRegression test f1 SCORE: 0.8240377062058131\n"
     ]
    }
   ],
   "source": [
    "# what are the test scores of the other metrics for LogisticRegression model\n",
    "print(f'LogisticRegression test RECALL: {recall_score(y_test, gs_log.predict(X_test))}')\n",
    "print(f'LogisticRegression test PRECISION: {precision_score(y_test, gs_log.predict(X_test))}')\n",
    "print(f'LogisticRegression test f1 SCORE: {f1_score(y_test, gs_log.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1457de",
   "metadata": {},
   "source": [
    "All scores apprear to not differ that much, with Precision being the lowest and Recall being the highest.<br>\n",
    "F1 score outperforms that of baseline, and KNN and RandomForest with hyperparameter tuning, but is slighlty worse than MNB with hyperparameter tuning.\n",
    "\n",
    "**Summary of the test scores for the Logistic Regression Model with hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fdbfb09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric        Score\n",
      "---------  --------\n",
      "Accuracy   0.8208\n",
      "Recall     0.8392\n",
      "Precision  0.809414\n",
      "f1 Score   0.824038\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Metric', 'Score'],\n",
    "                ['Accuracy', gs_log.score(X_test, y_test)],\n",
    "               ['Recall', recall_score(y_test, gs_log.predict(X_test))],\n",
    "               ['Precision', precision_score(y_test, gs_log.predict(X_test))],\n",
    "               ['f1 Score', f1_score(y_test, gs_log.predict(X_test))]],\n",
    "               headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3fe65e",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM) with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d8e48494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline for SVM\n",
    "pipe_svm = Pipeline([\n",
    "    ('cvec', CountVectorizer()), # instantiate CountVectorizer\n",
    "    ('svm', svm.SVC()) # instantiate SVM\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a781c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svm_params = {\n",
    "    'cvec__max_features': [None, 1000, 2000, 3000],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__max_df': [.8, .85],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'svm__kernel': ['rbf', 'linear'],\n",
    "    'svm__gamma': ['scale', 'auto'],\n",
    "    'svm__random_state': [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ee605f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV for SVM\n",
    "gs_svm = GridSearchCV(pipe_svm, \n",
    "                     param_grid=pipe_svm_params,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8399806b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('svm', SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.8, 0.85],\n",
       "                         'cvec__max_features': [None, 1000, 2000, 3000],\n",
       "                         'cvec__min_df': [1, 2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'svm__gamma': ['scale', 'auto'],\n",
       "                         'svm__kernel': ['rbf', 'linear'],\n",
       "                         'svm__random_state': [42]})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the training data to the SVM model\n",
    "gs_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "73729f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.8, 'cvec__max_features': None, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': None, 'svm__gamma': 'scale', 'svm__kernel': 'linear', 'svm__random_state': 42}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7993333333333333"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where are the best parameters in SVM model\n",
    "print(gs_svm.best_params_)\n",
    "\n",
    "# best score for SVM model\n",
    "gs_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c29e9bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM train accuracy score: 1.0\n",
      "SVM test accuracy score: 0.818\n"
     ]
    }
   ],
   "source": [
    "# what are the SVM accuracy scores?\n",
    "print(f'SVM train accuracy score: {gs_svm.score(X_train, y_train)}')\n",
    "print(f'SVM test accuracy score: {gs_svm.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff2beb",
   "metadata": {},
   "source": [
    "Interesting observations from Support Vector Machine:\n",
    "- Uni-grams to Bi-grams range worked the best for the model\n",
    "- No stop word removal worked best for the model\n",
    "- Linear worked better than Radial Basis Function(rbf) for the kernel parameter\n",
    "- Model is overfit, with the train score being 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "87a443c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression test RECALL: 0.84\n",
      "LogisticRegression test PRECISION: 0.8045977011494253\n",
      "LogisticRegression test f1 SCORE: 0.8219178082191781\n"
     ]
    }
   ],
   "source": [
    "# what are the test scores of the other metrics for SVM model\n",
    "print(f'LogisticRegression test RECALL: {recall_score(y_test, gs_svm.predict(X_test))}')\n",
    "print(f'LogisticRegression test PRECISION: {precision_score(y_test, gs_svm.predict(X_test))}')\n",
    "print(f'LogisticRegression test f1 SCORE: {f1_score(y_test, gs_svm.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf61d8",
   "metadata": {},
   "source": [
    "All scores apprear to not differ that much, with Precision being the lowest and Recall being the highest.<br>\n",
    "f1 score outperforms that of baseline, and KNN and RandomForest with hyperparameter tuning, but is slighlty worse than MNB and Logistic Regression with hyperparameter tuning.\n",
    "\n",
    "**Summary of the test scores for the Support Vector Machine Model with hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f9f2de08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric        Score\n",
      "---------  --------\n",
      "Accuracy   0.818\n",
      "Recall     0.84\n",
      "Precision  0.804598\n",
      "f1 Score   0.821918\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Metric', 'Score'],\n",
    "                ['Accuracy', gs_svm.score(X_test, y_test)],\n",
    "               ['Recall', recall_score(y_test, gs_svm.predict(X_test))],\n",
    "               ['Precision', precision_score(y_test, gs_svm.predict(X_test))],\n",
    "               ['f1 Score', f1_score(y_test, gs_svm.predict(X_test))]],\n",
    "               headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc28e79",
   "metadata": {},
   "source": [
    "## Summary of modelling scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "163a8ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                      Accuracy    Recall    Precision    f1 Score\n",
      "-----------------------  ----------  --------  -----------  ----------\n",
      "Baseline                     0.6076    0.6392     0.601204    0.61962\n",
      "k-Nearest Neighbors          0.6824    0.9008     0.626949    0.73933\n",
      "Random Forest                0.7932    0.8624     0.757554    0.806584\n",
      "Multinomial Naive Bayes      0.842     0.8512     0.835821    0.84344\n",
      "Logistic Regression          0.8208    0.8392     0.809414    0.824038\n",
      "Support Vector Machine       0.818     0.84       0.804598    0.821918\n",
      "\n",
      "The Baseline model being k-Nearest Neighbors without any hyperparameter tuning.\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Model', 'Accuracy', 'Recall', 'Precision', 'f1 Score'],\n",
    "                ['Baseline', pipe_knn_base.score(X_test, y_test), recall_score(y_test, pipe_knn_base.predict(X_test)), precision_score(y_test, pipe_knn_base.predict(X_test)), f1_score(y_test, pipe_knn_base.predict(X_test))],\n",
    "               ['k-Nearest Neighbors', gs_knn.score(X_test, y_test), recall_score(y_test, gs_knn.predict(X_test)), precision_score(y_test, gs_knn.predict(X_test)), f1_score(y_test, gs_knn.predict(X_test))],\n",
    "               ['Random Forest', gs_rf.score(X_test, y_test), recall_score(y_test, gs_rf.predict(X_test)), precision_score(y_test, gs_rf.predict(X_test)), f1_score(y_test, gs_rf.predict(X_test))],\n",
    "               ['Multinomial Naive Bayes', gs_nb.score(X_test, y_test), recall_score(y_test, gs_nb.predict(X_test)), precision_score(y_test, gs_nb.predict(X_test)), f1_score(y_test, gs_nb.predict(X_test))],\n",
    "               ['Logistic Regression', gs_log.score(X_test, y_test), recall_score(y_test, gs_log.predict(X_test)), precision_score(y_test, gs_log.predict(X_test)), f1_score(y_test, gs_log.predict(X_test))],\n",
    "               ['Support Vector Machine', gs_svm.score(X_test, y_test), recall_score(y_test, gs_svm.predict(X_test)), precision_score(y_test, gs_svm.predict(X_test)), f1_score(y_test, gs_svm.predict(X_test))]],\n",
    "               headers='firstrow'))\n",
    "\n",
    "print('') # leave a space\n",
    "\n",
    "print('The Baseline model being k-Nearest Neighbors without any hyperparameter tuning.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13330b6",
   "metadata": {},
   "source": [
    "As can be seen from the table above, Multinomial Naive Bayes has the best accuracy, precision and f1 score, f1 score being the most important metric in this project. \n",
    "\n",
    "k-Nearest Neighbors has the best recall.\n",
    "\n",
    "As Multinomial Naive Bayes has the highest number of best metrics, especially the f1 score, it will serve as our main chosen model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ccf89b",
   "metadata": {},
   "source": [
    "# References\n",
    "1. https://www.analyticsvidhya.com/blog/2020/11/a-tour-of-evaluation-metrics-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135a577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
