{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d65b49e2",
   "metadata": {},
   "source": [
    "# Part 3 - Preprocessing, Modelling and Conclusions & Recommendations\n",
    "\n",
    "This notebook will cover:\n",
    "\n",
    "- Selection of the X and y features\n",
    "- Modelling using various model types:\n",
    "    - K-Nearest Neighbours\n",
    "    - Random Forest\n",
    "    - Multinomial Naive Bayes\n",
    "    - Logistic Regression\n",
    "    - Support Vector Machine\n",
    "- Evaluation of chosen model\n",
    "- Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e29c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, plot_roc_curve, roc_auc_score, recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e47f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>new_text</th>\n",
       "      <th>newtext_length</th>\n",
       "      <th>newtext_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Woman self-isolates in plane toilet for five h...</td>\n",
       "      <td>1640966006</td>\n",
       "      <td>101</td>\n",
       "      <td>14</td>\n",
       "      <td>woman self isolates in plane toilet for five h...</td>\n",
       "      <td>98</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Gwyneth Paltrow Touts New Diamond-Encrusted Tr...</td>\n",
       "      <td>1640955671</td>\n",
       "      <td>89</td>\n",
       "      <td>11</td>\n",
       "      <td>gwyneth paltrow tout new diamond encrusted tre...</td>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Artist Crafting Music Box Hopes It Delights At...</td>\n",
       "      <td>1640955669</td>\n",
       "      <td>81</td>\n",
       "      <td>13</td>\n",
       "      <td>artist crafting music box hope it delight at l...</td>\n",
       "      <td>79</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Homeowner Trying To Smoke Out Snakes Accidenta...</td>\n",
       "      <td>1640955668</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>homeowner trying to smoke out snake accidental...</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Dictionary.Com Names ‘Allyship’ 2021 Word Of T...</td>\n",
       "      <td>1640955667</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>dictionary com name allyship 2021 word of the ...</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit                                              title  \\\n",
       "0  nottheonion  Woman self-isolates in plane toilet for five h...   \n",
       "1     TheOnion  Gwyneth Paltrow Touts New Diamond-Encrusted Tr...   \n",
       "2     TheOnion  Artist Crafting Music Box Hopes It Delights At...   \n",
       "3     TheOnion  Homeowner Trying To Smoke Out Snakes Accidenta...   \n",
       "4     TheOnion  Dictionary.Com Names ‘Allyship’ 2021 Word Of T...   \n",
       "\n",
       "   created_utc  title_length  title_word_count  \\\n",
       "0   1640966006           101                14   \n",
       "1   1640955671            89                11   \n",
       "2   1640955669            81                13   \n",
       "3   1640955668            66                10   \n",
       "4   1640955667            53                 8   \n",
       "\n",
       "                                            new_text  newtext_length  \\\n",
       "0  woman self isolates in plane toilet for five h...              98   \n",
       "1  gwyneth paltrow tout new diamond encrusted tre...              87   \n",
       "2  artist crafting music box hope it delight at l...              79   \n",
       "3  homeowner trying to smoke out snake accidental...              64   \n",
       "4  dictionary com name allyship 2021 word of the ...              50   \n",
       "\n",
       "   newtext_word_count  \n",
       "0                  16  \n",
       "1                  12  \n",
       "2                  14  \n",
       "3                  10  \n",
       "4                   9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the dataset\n",
    "onion_or_not = pd.read_csv('../Datasets/onion_or_not.csv')\n",
    "print(onion_or_not.shape)\n",
    "onion_or_not.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb58aa",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af1e64",
   "metadata": {},
   "source": [
    "### Generating Binary Classifier Column\n",
    "\n",
    "Since we want to create a model that will effectively predict which news is fake, we will use TheOnion as positive, since it is satire and not real news.\n",
    "\n",
    "\n",
    "**1: TheOnion<br>\n",
    "0: nottheonion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a113f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>new_text</th>\n",
       "      <th>newtext_length</th>\n",
       "      <th>newtext_word_count</th>\n",
       "      <th>onion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>Woman self-isolates in plane toilet for five h...</td>\n",
       "      <td>1640966006</td>\n",
       "      <td>101</td>\n",
       "      <td>14</td>\n",
       "      <td>woman self isolates in plane toilet for five h...</td>\n",
       "      <td>98</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Gwyneth Paltrow Touts New Diamond-Encrusted Tr...</td>\n",
       "      <td>1640955671</td>\n",
       "      <td>89</td>\n",
       "      <td>11</td>\n",
       "      <td>gwyneth paltrow tout new diamond encrusted tre...</td>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Artist Crafting Music Box Hopes It Delights At...</td>\n",
       "      <td>1640955669</td>\n",
       "      <td>81</td>\n",
       "      <td>13</td>\n",
       "      <td>artist crafting music box hope it delight at l...</td>\n",
       "      <td>79</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Homeowner Trying To Smoke Out Snakes Accidenta...</td>\n",
       "      <td>1640955668</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>homeowner trying to smoke out snake accidental...</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Dictionary.Com Names ‘Allyship’ 2021 Word Of T...</td>\n",
       "      <td>1640955667</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>dictionary com name allyship 2021 word of the ...</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit                                              title  \\\n",
       "0  nottheonion  Woman self-isolates in plane toilet for five h...   \n",
       "1     TheOnion  Gwyneth Paltrow Touts New Diamond-Encrusted Tr...   \n",
       "2     TheOnion  Artist Crafting Music Box Hopes It Delights At...   \n",
       "3     TheOnion  Homeowner Trying To Smoke Out Snakes Accidenta...   \n",
       "4     TheOnion  Dictionary.Com Names ‘Allyship’ 2021 Word Of T...   \n",
       "\n",
       "   created_utc  title_length  title_word_count  \\\n",
       "0   1640966006           101                14   \n",
       "1   1640955671            89                11   \n",
       "2   1640955669            81                13   \n",
       "3   1640955668            66                10   \n",
       "4   1640955667            53                 8   \n",
       "\n",
       "                                            new_text  newtext_length  \\\n",
       "0  woman self isolates in plane toilet for five h...              98   \n",
       "1  gwyneth paltrow tout new diamond encrusted tre...              87   \n",
       "2  artist crafting music box hope it delight at l...              79   \n",
       "3  homeowner trying to smoke out snake accidental...              64   \n",
       "4  dictionary com name allyship 2021 word of the ...              50   \n",
       "\n",
       "   newtext_word_count  onion  \n",
       "0                  16      0  \n",
       "1                  12      1  \n",
       "2                  14      1  \n",
       "3                  10      1  \n",
       "4                   9      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create column for 1s and 0s for subreddit\n",
    "# TheOnion : 1, notthe onion : 0\n",
    "onion_or_not['onion'] = [1 if value == 'TheOnion' else 0 for value in onion_or_not.subreddit.values]\n",
    "onion_or_not.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4c7c4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5000\n",
      "1    5000\n",
      "Name: onion, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: onion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as stated in the previous notebook, the classes are perfectly balanced\n",
    "print(onion_or_not.onion.value_counts(normalize=False))\n",
    "onion_or_not.onion.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94502158",
   "metadata": {},
   "source": [
    "### The X and y features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e834cc",
   "metadata": {},
   "source": [
    "We will use the `new_text` to predict whether a title is from the onion or not. The `new_text` is the tokenized and lemmatized version of the original `title` text.<br>\n",
    "Hence, our X will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93120ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    woman self isolates in plane toilet for five h...\n",
       "1    gwyneth paltrow tout new diamond encrusted tre...\n",
       "2    artist crafting music box hope it delight at l...\n",
       "3    homeowner trying to smoke out snake accidental...\n",
       "4    dictionary com name allyship 2021 word of the ...\n",
       "Name: new_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = onion_or_not.new_text\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb5240",
   "metadata": {},
   "source": [
    "Our y will simply be the `onion` column of 1s and 0s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f5454ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: onion, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = onion_or_not.onion\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6718ced5",
   "metadata": {},
   "source": [
    "### Train, Test and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8c11eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test and split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0834f10",
   "metadata": {},
   "source": [
    "## Important metrics for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf9c34",
   "metadata": {},
   "source": [
    "### Which is worse, FALSE POSITIVES or FALSE NEGATIVES?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b96b2",
   "metadata": {},
   "source": [
    "**False Positive - News that is real, but wrongly classified as fake.<br>\n",
    "False Negative - News that is fake, but wrongly classified as real.**<br>\n",
    "\n",
    "False positives are important, as the implications of classifying real news as fake can be serious. For example, real news about vaccines being classified as fake can have a serious impact on the healthcare system and vaccination efforts of a nation.\n",
    "\n",
    "That said, false negatives hold equal importance as well. For example, classifying a fake news about a terrorist attack as real will cause undue panic and anxiety, which will cause unecessary stress the security and defence personnel.\n",
    "\n",
    "The metrics we will use to evaluate the model are:\n",
    "\n",
    "- Accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "- Recall = TP/(TP + FN)\n",
    "- Precision = TP/(TP + FP)\n",
    "- **f1 Score**\n",
    "\n",
    "Where TP, TN, FP and FN are **True Positives, True Negatives, False Positives and False Negatives** respectively.\n",
    "\n",
    "Since avoiding both false positives and false negatives are equally important for our problem, we need a trade-off between precision and recall. We will thus **use the f1 score as the main metric**. The f1 score is defined as the harmonic mean of precision and recall.<sup>1</sup><br>\n",
    "$$\n",
    "F1 = 2*\\frac{(\\text{Precision}*\\text{Recall})} {(\\text{Precision} + \\text{Recall})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53407dc8",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728081d",
   "metadata": {},
   "source": [
    "We will model the data using the following models:\n",
    "- K-Nearest Neighbours\n",
    "- Random Forest\n",
    "- Multinomial Naive Bayes\n",
    "- Support Vector Machine\n",
    "- Logistic Regression\n",
    "\n",
    "The model with the best metric will be chosen as our primary model, on which we will perform further study and draw reccomendations and conclusions from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74be4fc",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "It is tempting to just use accuracy score of 0.5 as the baseline. This however, would be pointless as it is overly basic, and the dataset is deliberately balanced in the first place. We will thus use **k-Nearest Neighbours as the baseline model**:\n",
    "- It is a proper machine-learning model, yet basic enough for a baseline evaluation.\n",
    "- It will give us a feel of the dataset, such as whether it overfits, or if there are more false positives than false negatives etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db511242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create KNN pipeline\n",
    "# no default CountVectorizer and KNN will be used as it is a baseline\n",
    "pipe_knn_base = Pipeline([\n",
    "    ('cvec', CountVectorizer()), # instantiate CountVectorizer\n",
    "    ('knn', KNeighborsClassifier()) # Instantiate KNN\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e50cb608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer()), ('knn', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the train data\n",
    "pipe_knn_base.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7444e372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline train accuracy score: 0.7193333333333334\n",
      "Baseline test accuracy score: 0.58\n"
     ]
    }
   ],
   "source": [
    "# get the score on the train and test sets\n",
    "print(f'Baseline train accuracy score: {pipe_knn_base.score(X_train, y_train)}')\n",
    "print(f'Baseline test accuracy score: {pipe_knn_base.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f039f2",
   "metadata": {},
   "source": [
    "The model is overfit, as can be seen by the difference between the train and test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3d430a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test RECALL: 0.5688\n",
      "Baseline test PRECISION: 0.5818330605564648\n",
      "Baseline test f1 SCORE: 0.5752427184466019\n"
     ]
    }
   ],
   "source": [
    "# what are the other test set metrics for baseline KNN model?\n",
    "print(f'Baseline test RECALL: {recall_score(y_test, pipe_knn_base.predict(X_test))}')\n",
    "print(f'Baseline test PRECISION: {precision_score(y_test, pipe_knn_base.predict(X_test))}')\n",
    "print(f'Baseline test f1 SCORE: {f1_score(y_test, pipe_knn_base.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4b6354",
   "metadata": {},
   "source": [
    "**Summary of the test scores for the baseline KNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95103eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric        Score\n",
      "---------  --------\n",
      "Accuracy   0.58\n",
      "Recall     0.5688\n",
      "Precision  0.581833\n",
      "f1 Score   0.575243\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Metric', 'Score'],\n",
    "                ['Accuracy', pipe_knn_base.score(X_test, y_test)],\n",
    "               ['Recall', recall_score(y_test, pipe_knn_base.predict(X_test))],\n",
    "               ['Precision', precision_score(y_test, pipe_knn_base.predict(X_test))],\n",
    "               ['f1 Score', f1_score(y_test, pipe_knn_base.predict(X_test))]],\n",
    "               headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c274ad",
   "metadata": {},
   "source": [
    "Scores for the metrics are relatively close to each other, around **0.57 - 0.58**, and are overall not that good.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd02cd8",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors (KNN) Model Hyperparameter Tuning\n",
    "Since the baseline performed rather poorly, we will tune the hyperparameters of the the KNN model to see if the score can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b5def40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create KNN pipeline\n",
    "pipe_knn = Pipeline([\n",
    "    ('cvec', CountVectorizer()), # instantiate CountVectorizer\n",
    "    ('knn', KNeighborsClassifier()) # Instantiate KNN\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8af11f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer and KNN parameters\n",
    "pipe_knn_params = {\n",
    "    'cvec__max_features': [None, 1000, 2000, 3000],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__max_df': [.8, .85],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'knn__n_neighbors': [1, 3, 5, 7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "201bfee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch for KNN\n",
    "gs_knn = GridSearchCV(pipe_knn,\n",
    "                     param_grid=pipe_knn_params,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b345487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.8, 0.85],\n",
       "                         'cvec__max_features': [None, 1000, 2000, 3000],\n",
       "                         'cvec__min_df': [1, 2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'knn__n_neighbors': [1, 3, 5, 7]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the training data\n",
    "gs_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03bf4497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.8, 'cvec__max_features': None, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': None, 'knn__n_neighbors': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5985333333333334"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where are the best parameters in KNN model\n",
    "print(gs_knn.best_params_)\n",
    "\n",
    "# best score for KNN model\n",
    "gs_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9481b662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN train accuracy score: 1.0\n",
      "KNN test accuracy score: 0.6048\n"
     ]
    }
   ],
   "source": [
    "# what are the KNN accuracy scores?\n",
    "print(f'KNN train accuracy score: {gs_knn.score(X_train, y_train)}')\n",
    "print(f'KNN test accuracy score: {gs_knn.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7344d32b",
   "metadata": {},
   "source": [
    "A number of observations can be seen by comparing the KNN model with hyperparameter tuning with the baseline.\n",
    "- No removal of stopwords worked best for this model.\n",
    "- Uni-grams only worked best for this model\n",
    "- The nearest neighbours that worked best for this model is **1**.\n",
    "- Although scores have improved slightly over the baseline, overfitting is still present, and severe, with train accuracy being **1.0**.\n",
    "\n",
    "This will help with adjusting the parameters for the other models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5eae490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN test RECALL: 0.6952\n",
      "KNN test PRECISION: 0.5887533875338753\n",
      "KNN test f1 SCORE: 0.6375641966250917\n"
     ]
    }
   ],
   "source": [
    "# what are the test scores of the other metrics for KNN model\n",
    "print(f'KNN test RECALL: {recall_score(y_test, gs_knn.predict(X_test))}')\n",
    "print(f'KNN test PRECISION: {precision_score(y_test, gs_knn.predict(X_test))}')\n",
    "print(f'KNN test f1 SCORE: {f1_score(y_test, gs_knn.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db57e1a",
   "metadata": {},
   "source": [
    "There is significant improvement for Recall, and f1 Scores relative to the baseline, and marginal improvement for accuracy and recall relative to the baseline.<br>\n",
    "Although there is improvement over the baseline, it is not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee471f25",
   "metadata": {},
   "source": [
    "**Summary of the test scores for the KNN Model with hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7f218cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric        Score\n",
      "---------  --------\n",
      "Accuracy   0.6048\n",
      "Recall     0.6952\n",
      "Precision  0.588753\n",
      "f1 Score   0.637564\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Metric', 'Score'],\n",
    "                ['Accuracy', gs_knn.score(X_test, y_test)],\n",
    "               ['Recall', recall_score(y_test, gs_knn.predict(X_test))],\n",
    "               ['Precision', precision_score(y_test, gs_knn.predict(X_test))],\n",
    "               ['f1 Score', f1_score(y_test, gs_knn.predict(X_test))]],\n",
    "               headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe2b3e",
   "metadata": {},
   "source": [
    "### Random Forest with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ac5f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for RandomForest\n",
    "pipe_rf = Pipeline([\n",
    "    ('cvec', CountVectorizer()), # instantiate CountVectorizer\n",
    "    ('rf', RandomForestClassifier()) # instantiate RandomForest\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bd8e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer and RandomForest parameters\n",
    "pipe_rf_params = {\n",
    "    'cvec__max_features': [None, 1000, 2000, 3000],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__max_df': [.8, .85],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'rf__n_estimators': [100, 200, 300],\n",
    "    'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
    "    'rf__random_state': [42],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21659bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch for RandomForest\n",
    "gs_rf = GridSearchCV(pipe_rf,\n",
    "                     param_grid=pipe_rf_params,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ab4ad48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.8, 0.85],\n",
       "                         'cvec__max_features': [None, 1000, 2000, 3000],\n",
       "                         'cvec__min_df': [1, 2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
       "                         'rf__n_estimators': [100, 200, 300],\n",
       "                         'rf__random_state': [42]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the training data to the RandomForest model\n",
    "gs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c16ce95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.8, 'cvec__max_features': None, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': None, 'rf__max_depth': None, 'rf__n_estimators': 300, 'rf__random_state': 42}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7410666666666667"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where are the best parameters in RandomForest model\n",
    "print(gs_rf.best_params_)\n",
    "\n",
    "# best score for RandForest model\n",
    "gs_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e45e9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest train accuracy score: 1.0\n",
      "RandomForest test accuracy score: 0.7496\n"
     ]
    }
   ],
   "source": [
    "# what are the RandomForest accuracy scores?\n",
    "print(f'RandomForest train accuracy score: {gs_rf.score(X_train, y_train)}')\n",
    "print(f'RandomForest test accuracy score: {gs_rf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ced9fca",
   "metadata": {},
   "source": [
    "Some interesting observations for RandomForest:\n",
    "- Better accuracy than KNN with hyperparameter tuning and baseline, but still overfit, with train score being **1.0**.\n",
    "- Uni-grams to bi-gram range work best for this model.\n",
    "- No stop words were removed, which was the best for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fcc1490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest test RECALL: 0.7128\n",
      "RandomForest test PRECISION: 0.7694300518134715\n",
      "RandomForest test f1 SCORE: 0.7400332225913621\n"
     ]
    }
   ],
   "source": [
    "# what are the test scores of the other metrics for RandomForest model\n",
    "print(f'RandomForest test RECALL: {recall_score(y_test, gs_rf.predict(X_test))}')\n",
    "print(f'RandomForest test PRECISION: {precision_score(y_test, gs_rf.predict(X_test))}')\n",
    "print(f'RandomForest test f1 SCORE: {f1_score(y_test, gs_rf.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b077a4",
   "metadata": {},
   "source": [
    "A significant improvement over the KNN with hyperparameter tuning and baseline across all metrics.<br>\n",
    "f1 score is starting to look more promising at **0.74**, f1 score being the most important metric in determining the chosen model for this project.\n",
    "\n",
    "**Summary of the test scores for the RandomForest Model with hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ab55197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric        Score\n",
      "---------  --------\n",
      "Accuracy   0.7496\n",
      "Recall     0.7128\n",
      "Precision  0.76943\n",
      "f1 Score   0.740033\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Metric', 'Score'],\n",
    "                ['Accuracy', gs_rf.score(X_test, y_test)],\n",
    "               ['Recall', recall_score(y_test, gs_rf.predict(X_test))],\n",
    "               ['Precision', precision_score(y_test, gs_rf.predict(X_test))],\n",
    "               ['f1 Score', f1_score(y_test, gs_rf.predict(X_test))]],\n",
    "               headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eea020",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes (MNB) with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42cf3d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline for MNB\n",
    "pipe_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()), # instantiate CountVectorizer\n",
    "    ('nb', MultinomialNB()) # instantiate MNB\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bc02a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer and MNB parameters\n",
    "pipe_nb_params = {\n",
    "    'cvec__max_features': [None, 1000, 2000, 3000],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__max_df': [.8, .85],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'nb__alpha': np.linspace(0.5, 1.8, 8),\n",
    "    'nb__fit_prior': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fee8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV for MNB\n",
    "gs_nb = GridSearchCV(pipe_nb, \n",
    "                     param_grid=pipe_nb_params,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6707e95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.8, 0.85],\n",
       "                         'cvec__max_features': [None, 1000, 2000, 3000],\n",
       "                         'cvec__min_df': [1, 2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'nb__alpha': array([0.5       , 0.68571429, 0.87142857, 1.05714286, 1.24285714,\n",
       "       1.42857143, 1.61428571, 1.8       ]),\n",
       "                         'nb__fit_prior': [True, False]})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the training data to the MNB model\n",
    "gs_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d8fc8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.8, 'cvec__max_features': None, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': None, 'nb__alpha': 1.6142857142857143, 'nb__fit_prior': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7847999999999999"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where are the best parameters in MNB model\n",
    "print(gs_nb.best_params_)\n",
    "\n",
    "# best score for MNB model\n",
    "gs_nb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "573101eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB train accuracy score: 0.984\n",
      "MNB test accuracy score: 0.7908\n"
     ]
    }
   ],
   "source": [
    "# what are the MNB accuracy scores?\n",
    "print(f'MNB train accuracy score: {gs_nb.score(X_train, y_train)}')\n",
    "print(f'MNB test accuracy score: {gs_nb.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315632a0",
   "metadata": {},
   "source": [
    "Interesting observations from MNB:\n",
    "- Uni-grams to bi-grams range worked the best\n",
    "- No stop word removal worked best for the model\n",
    "- alpha value of **1.6142857142857143**\n",
    "- Model is strong predictor with a relatively high test score, but still overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07ac3b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB test RECALL: 0.8184\n",
      "MNB test PRECISION: 0.775587566338135\n",
      "MNB test f1 SCORE: 0.7964188400155703\n"
     ]
    }
   ],
   "source": [
    "# what are the test scores of the other metrics for MNB model\n",
    "print(f'MNB test RECALL: {recall_score(y_test, gs_nb.predict(X_test))}')\n",
    "print(f'MNB test PRECISION: {precision_score(y_test, gs_nb.predict(X_test))}')\n",
    "print(f'MNB test f1 SCORE: {f1_score(y_test, gs_nb.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e755da6",
   "metadata": {},
   "source": [
    "All metrics have relatively high scores compared , with RECALL being the highest at **0.8184**, and PRECISION being the lowest at **0.7756**, which is indicative that the model predicted more false positives than false negatives.<br>\n",
    "f1 score outperforms that of baseline, and KNN and RandomForest with hyperparameter tuning by a significant margin.\n",
    "\n",
    "**Summary of the test scores for the RandomForest Model with hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "603664c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric        Score\n",
      "---------  --------\n",
      "Accuracy   0.7908\n",
      "Recall     0.8184\n",
      "Precision  0.775588\n",
      "f1 Score   0.796419\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Metric', 'Score'],\n",
    "                ['Accuracy', gs_nb.score(X_test, y_test)],\n",
    "               ['Recall', recall_score(y_test, gs_nb.predict(X_test))],\n",
    "               ['Precision', precision_score(y_test, gs_nb.predict(X_test))],\n",
    "               ['f1 Score', f1_score(y_test, gs_nb.predict(X_test))]],\n",
    "               headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1fb9c5",
   "metadata": {},
   "source": [
    "### Logistic Regression with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a328bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline for LogisticRegression\n",
    "pipe_log = Pipeline([\n",
    "    ('cvec', CountVectorizer()), # instantiate CountVectorizer\n",
    "    ('log', LogisticRegression()) # instantiate LogisticRegression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b03c5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_log_params = {\n",
    "    'cvec__max_features': [None, 1000, 2000, 3000],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__max_df': [.8, .85],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'log__penalty': ['l1', 'l2'],\n",
    "    'log__max_iter': [100, 300, 500],\n",
    "    'log__random_state': [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8cb6fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV for Logistic Regression\n",
    "gs_log = GridSearchCV(pipe_log, \n",
    "                     param_grid=pipe_log_params,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cc53cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.76413333        nan 0.76413333        nan 0.76413333\n",
      "        nan 0.74533333        nan 0.74533333        nan 0.74533333\n",
      "        nan 0.77626667        nan 0.77626667        nan 0.77626667\n",
      "        nan 0.75893333        nan 0.75893333        nan 0.75893333\n",
      "        nan 0.7732            nan 0.7732            nan 0.7732\n",
      "        nan 0.75786667        nan 0.75786667        nan 0.75786667\n",
      "        nan 0.7624            nan 0.7624            nan 0.7624\n",
      "        nan 0.74426667        nan 0.74426667        nan 0.74426667\n",
      "        nan 0.77133333        nan 0.77133333        nan 0.77133333\n",
      "        nan 0.74946667        nan 0.74946667        nan 0.74946667\n",
      "        nan 0.7724            nan 0.7724            nan 0.7724\n",
      "        nan 0.7496            nan 0.7496            nan 0.7496\n",
      "        nan 0.7596            nan 0.7596            nan 0.7596\n",
      "        nan 0.73693333        nan 0.73693333        nan 0.73693333\n",
      "        nan 0.76453333        nan 0.76453333        nan 0.76453333\n",
      "        nan 0.74226667        nan 0.74226667        nan 0.74226667\n",
      "        nan 0.76546667        nan 0.76546667        nan 0.76546667\n",
      "        nan 0.7436            nan 0.7436            nan 0.7436\n",
      "        nan 0.73426667        nan 0.73426667        nan 0.73426667\n",
      "        nan 0.7088            nan 0.7088            nan 0.7088\n",
      "        nan 0.7352            nan 0.7352            nan 0.7352\n",
      "        nan 0.7096            nan 0.7096            nan 0.7096\n",
      "        nan 0.73546667        nan 0.73546667        nan 0.73546667\n",
      "        nan 0.70933333        nan 0.70933333        nan 0.70933333\n",
      "        nan 0.73613333        nan 0.73613333        nan 0.73613333\n",
      "        nan 0.70773333        nan 0.70773333        nan 0.70773333\n",
      "        nan 0.73586667        nan 0.73586667        nan 0.73586667\n",
      "        nan 0.70933333        nan 0.70933333        nan 0.70933333\n",
      "        nan 0.7352            nan 0.7352            nan 0.7352\n",
      "        nan 0.70893333        nan 0.70893333        nan 0.70893333\n",
      "        nan 0.73373333        nan 0.73373333        nan 0.73373333\n",
      "        nan 0.7084            nan 0.7084            nan 0.7084\n",
      "        nan 0.73546667        nan 0.73546667        nan 0.73546667\n",
      "        nan 0.70973333        nan 0.70973333        nan 0.70973333\n",
      "        nan 0.73533333        nan 0.73533333        nan 0.73533333\n",
      "        nan 0.7104            nan 0.7104            nan 0.7104\n",
      "        nan 0.748             nan 0.748             nan 0.748\n",
      "        nan 0.72333333        nan 0.72333333        nan 0.72333333\n",
      "        nan 0.74613333        nan 0.74613333        nan 0.74613333\n",
      "        nan 0.7232            nan 0.7232            nan 0.7232\n",
      "        nan 0.7448            nan 0.7448            nan 0.7448\n",
      "        nan 0.72453333        nan 0.72453333        nan 0.72453333\n",
      "        nan 0.7504            nan 0.7504            nan 0.7504\n",
      "        nan 0.72346667        nan 0.72346667        nan 0.72346667\n",
      "        nan 0.7456            nan 0.7456            nan 0.7456\n",
      "        nan 0.72373333        nan 0.72373333        nan 0.72373333\n",
      "        nan 0.7448            nan 0.7448            nan 0.7448\n",
      "        nan 0.72706667        nan 0.72706667        nan 0.72706667\n",
      "        nan 0.7472            nan 0.7472            nan 0.7472\n",
      "        nan 0.72266667        nan 0.72266667        nan 0.72266667\n",
      "        nan 0.74453333        nan 0.74453333        nan 0.74453333\n",
      "        nan 0.72506667        nan 0.72506667        nan 0.72506667\n",
      "        nan 0.74413333        nan 0.74413333        nan 0.74413333\n",
      "        nan 0.7268            nan 0.7268            nan 0.7268\n",
      "        nan 0.75506667        nan 0.75506667        nan 0.75506667\n",
      "        nan 0.73026667        nan 0.73026667        nan 0.73026667\n",
      "        nan 0.75346667        nan 0.75346667        nan 0.75346667\n",
      "        nan 0.73506667        nan 0.73506667        nan 0.73506667\n",
      "        nan 0.754             nan 0.754             nan 0.754\n",
      "        nan 0.73466667        nan 0.73466667        nan 0.73466667\n",
      "        nan 0.7552            nan 0.7552            nan 0.7552\n",
      "        nan 0.72906667        nan 0.72906667        nan 0.72906667\n",
      "        nan 0.7528            nan 0.7528            nan 0.7528\n",
      "        nan 0.73506667        nan 0.73506667        nan 0.73506667\n",
      "        nan 0.75466667        nan 0.75466667        nan 0.75466667\n",
      "        nan 0.736             nan 0.736             nan 0.736\n",
      "        nan 0.7544            nan 0.7544            nan 0.7544\n",
      "        nan 0.73026667        nan 0.73026667        nan 0.73026667\n",
      "        nan 0.75426667        nan 0.75426667        nan 0.75426667\n",
      "        nan 0.73413333        nan 0.73413333        nan 0.73413333\n",
      "        nan 0.75306667        nan 0.75306667        nan 0.75306667\n",
      "        nan 0.73786667        nan 0.73786667        nan 0.73786667\n",
      "        nan 0.76413333        nan 0.76413333        nan 0.76413333\n",
      "        nan 0.74533333        nan 0.74533333        nan 0.74533333\n",
      "        nan 0.77626667        nan 0.77626667        nan 0.77626667\n",
      "        nan 0.75893333        nan 0.75893333        nan 0.75893333\n",
      "        nan 0.7732            nan 0.7732            nan 0.7732\n",
      "        nan 0.75786667        nan 0.75786667        nan 0.75786667\n",
      "        nan 0.7624            nan 0.7624            nan 0.7624\n",
      "        nan 0.74426667        nan 0.74426667        nan 0.74426667\n",
      "        nan 0.77133333        nan 0.77133333        nan 0.77133333\n",
      "        nan 0.74946667        nan 0.74946667        nan 0.74946667\n",
      "        nan 0.7724            nan 0.7724            nan 0.7724\n",
      "        nan 0.7496            nan 0.7496            nan 0.7496\n",
      "        nan 0.7596            nan 0.7596            nan 0.7596\n",
      "        nan 0.73693333        nan 0.73693333        nan 0.73693333\n",
      "        nan 0.76453333        nan 0.76453333        nan 0.76453333\n",
      "        nan 0.74226667        nan 0.74226667        nan 0.74226667\n",
      "        nan 0.76546667        nan 0.76546667        nan 0.76546667\n",
      "        nan 0.7436            nan 0.7436            nan 0.7436\n",
      "        nan 0.73426667        nan 0.73426667        nan 0.73426667\n",
      "        nan 0.7088            nan 0.7088            nan 0.7088\n",
      "        nan 0.7352            nan 0.7352            nan 0.7352\n",
      "        nan 0.7096            nan 0.7096            nan 0.7096\n",
      "        nan 0.73546667        nan 0.73546667        nan 0.73546667\n",
      "        nan 0.70933333        nan 0.70933333        nan 0.70933333\n",
      "        nan 0.73613333        nan 0.73613333        nan 0.73613333\n",
      "        nan 0.70773333        nan 0.70773333        nan 0.70773333\n",
      "        nan 0.73586667        nan 0.73586667        nan 0.73586667\n",
      "        nan 0.70933333        nan 0.70933333        nan 0.70933333\n",
      "        nan 0.7352            nan 0.7352            nan 0.7352\n",
      "        nan 0.70893333        nan 0.70893333        nan 0.70893333\n",
      "        nan 0.73373333        nan 0.73373333        nan 0.73373333\n",
      "        nan 0.7084            nan 0.7084            nan 0.7084\n",
      "        nan 0.73546667        nan 0.73546667        nan 0.73546667\n",
      "        nan 0.70973333        nan 0.70973333        nan 0.70973333\n",
      "        nan 0.73533333        nan 0.73533333        nan 0.73533333\n",
      "        nan 0.7104            nan 0.7104            nan 0.7104\n",
      "        nan 0.748             nan 0.748             nan 0.748\n",
      "        nan 0.72333333        nan 0.72333333        nan 0.72333333\n",
      "        nan 0.74613333        nan 0.74613333        nan 0.74613333\n",
      "        nan 0.7232            nan 0.7232            nan 0.7232\n",
      "        nan 0.7448            nan 0.7448            nan 0.7448\n",
      "        nan 0.72453333        nan 0.72453333        nan 0.72453333\n",
      "        nan 0.7504            nan 0.7504            nan 0.7504\n",
      "        nan 0.72346667        nan 0.72346667        nan 0.72346667\n",
      "        nan 0.7456            nan 0.7456            nan 0.7456\n",
      "        nan 0.72373333        nan 0.72373333        nan 0.72373333\n",
      "        nan 0.7448            nan 0.7448            nan 0.7448\n",
      "        nan 0.72706667        nan 0.72706667        nan 0.72706667\n",
      "        nan 0.7472            nan 0.7472            nan 0.7472\n",
      "        nan 0.72266667        nan 0.72266667        nan 0.72266667\n",
      "        nan 0.74453333        nan 0.74453333        nan 0.74453333\n",
      "        nan 0.72506667        nan 0.72506667        nan 0.72506667\n",
      "        nan 0.74413333        nan 0.74413333        nan 0.74413333\n",
      "        nan 0.7268            nan 0.7268            nan 0.7268\n",
      "        nan 0.75506667        nan 0.75506667        nan 0.75506667\n",
      "        nan 0.73026667        nan 0.73026667        nan 0.73026667\n",
      "        nan 0.75346667        nan 0.75346667        nan 0.75346667\n",
      "        nan 0.73506667        nan 0.73506667        nan 0.73506667\n",
      "        nan 0.754             nan 0.754             nan 0.754\n",
      "        nan 0.73466667        nan 0.73466667        nan 0.73466667\n",
      "        nan 0.7552            nan 0.7552            nan 0.7552\n",
      "        nan 0.72906667        nan 0.72906667        nan 0.72906667\n",
      "        nan 0.7528            nan 0.7528            nan 0.7528\n",
      "        nan 0.73506667        nan 0.73506667        nan 0.73506667\n",
      "        nan 0.75466667        nan 0.75466667        nan 0.75466667\n",
      "        nan 0.736             nan 0.736             nan 0.736\n",
      "        nan 0.7544            nan 0.7544            nan 0.7544\n",
      "        nan 0.73026667        nan 0.73026667        nan 0.73026667\n",
      "        nan 0.75426667        nan 0.75426667        nan 0.75426667\n",
      "        nan 0.73413333        nan 0.73413333        nan 0.73413333\n",
      "        nan 0.75306667        nan 0.75306667        nan 0.75306667\n",
      "        nan 0.73786667        nan 0.73786667        nan 0.73786667]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('log', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.8, 0.85],\n",
       "                         'cvec__max_features': [None, 1000, 2000, 3000],\n",
       "                         'cvec__min_df': [1, 2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'log__max_iter': [100, 300, 500],\n",
       "                         'log__penalty': ['l1', 'l2'],\n",
       "                         'log__random_state': [42]})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the training data to the LogisticRegression model\n",
    "gs_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "499d07ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.8, 'cvec__max_features': None, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': None, 'log__max_iter': 100, 'log__penalty': 'l2', 'log__random_state': 42}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7762666666666667"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where are the best parameters in LogisticRegression model\n",
    "print(gs_log.best_params_)\n",
    "\n",
    "# best score for LogisticRegression model\n",
    "gs_log.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93f08930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression train accuracy score: 0.9997333333333334\n",
      "LogisticRegression test accuracy score: 0.7852\n"
     ]
    }
   ],
   "source": [
    "# what are the LogisticRegression accuracy scores?\n",
    "print(f'LogisticRegression train accuracy score: {gs_log.score(X_train, y_train)}')\n",
    "print(f'LogisticRegression test accuracy score: {gs_log.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f0aece",
   "metadata": {},
   "source": [
    "Interesting observations with Logistic Regression:\n",
    "- Uni-grams to bi-grams worked the best for this model\n",
    "- No stop words were removed, which worked the best for this model\n",
    "- l2 penalty, ie Ridge Regression worked best for the model\n",
    "- Model is also overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f3465b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression test RECALL: 0.78\n",
      "LogisticRegression test PRECISION: 0.788197251414713\n",
      "LogisticRegression test f1 SCORE: 0.7840772014475271\n"
     ]
    }
   ],
   "source": [
    "# what are the test scores of the other metrics for LogisticRegression model\n",
    "print(f'LogisticRegression test RECALL: {recall_score(y_test, gs_log.predict(X_test))}')\n",
    "print(f'LogisticRegression test PRECISION: {precision_score(y_test, gs_log.predict(X_test))}')\n",
    "print(f'LogisticRegression test f1 SCORE: {f1_score(y_test, gs_log.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09afb9cd",
   "metadata": {},
   "source": [
    "The most consistent model so far, with scores of all metrics being arounf **0.78**.\n",
    "All scores are relatively high, with Precision being the highest at **0.7882** and Precision being the lowest at **0.78**, which is indicative that the model predicted more slightly more false negatives than false positives.<br>\n",
    "f1 score outperforms that of baseline, and KNN and RandomForest with hyperparameter tuning, but is slighlty worse than MNB with hyperparameter tuning.\n",
    "\n",
    "**Summary of the test scores for the Logistic Regression Model with hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c4dfe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric        Score\n",
      "---------  --------\n",
      "Accuracy   0.7852\n",
      "Recall     0.78\n",
      "Precision  0.788197\n",
      "f1 Score   0.784077\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Metric', 'Score'],\n",
    "                ['Accuracy', gs_log.score(X_test, y_test)],\n",
    "               ['Recall', recall_score(y_test, gs_log.predict(X_test))],\n",
    "               ['Precision', precision_score(y_test, gs_log.predict(X_test))],\n",
    "               ['f1 Score', f1_score(y_test, gs_log.predict(X_test))]],\n",
    "               headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef971dd1",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM) with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ebccc6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline for SVM\n",
    "pipe_svm = Pipeline([\n",
    "    ('cvec', CountVectorizer()), # instantiate CountVectorizer\n",
    "    ('svm', svm.SVC()) # instantiate SVM\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "323ce4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svm_params = {\n",
    "    'cvec__max_features': [None, 1000, 2000, 3000],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__max_df': [.8, .85],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'svm__kernel': ['rbf', 'linear'],\n",
    "    'svm__gamma': ['scale', 'auto'],\n",
    "    'svm__random_state': [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2cff264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV for SVM\n",
    "gs_svm = GridSearchCV(pipe_svm, \n",
    "                     param_grid=pipe_svm_params,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd5d0ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('svm', SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.8, 0.85],\n",
       "                         'cvec__max_features': [None, 1000, 2000, 3000],\n",
       "                         'cvec__min_df': [1, 2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'svm__gamma': ['scale', 'auto'],\n",
       "                         'svm__kernel': ['rbf', 'linear'],\n",
       "                         'svm__random_state': [42]})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the training data to the SVM model\n",
    "gs_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a356a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.8, 'cvec__max_features': None, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': None, 'svm__gamma': 'scale', 'svm__kernel': 'linear', 'svm__random_state': 42}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7694666666666666"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where are the best parameters in SVM model\n",
    "print(gs_svm.best_params_)\n",
    "\n",
    "# best score for SVM model\n",
    "gs_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04d2f6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM train accuracy score: 1.0\n",
      "SVM test accuracy score: 0.7804\n"
     ]
    }
   ],
   "source": [
    "# what are the SVM accuracy scores?\n",
    "print(f'SVM train accuracy score: {gs_svm.score(X_train, y_train)}')\n",
    "print(f'SVM test accuracy score: {gs_svm.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04c8e3",
   "metadata": {},
   "source": [
    "Interesting observations from Support Vector Machine:\n",
    "- Uni-grams tri-grams range worked the best for the model\n",
    "- No stop word removal worked best for the model\n",
    "- Linear worked better than Radial Basis Function(rbf) for the kernel parameter\n",
    "- Model is overfit, with the train score being 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f97a1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM test RECALL: 0.7784\n",
      "SVM test PRECISION: 0.7815261044176707\n",
      "SVM test f1 SCORE: 0.7799599198396793\n"
     ]
    }
   ],
   "source": [
    "# what are the test scores of the other metrics for SVM model\n",
    "print(f'SVM test RECALL: {recall_score(y_test, gs_svm.predict(X_test))}')\n",
    "print(f'SVM test PRECISION: {precision_score(y_test, gs_svm.predict(X_test))}')\n",
    "print(f'SVM test f1 SCORE: {f1_score(y_test, gs_svm.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c881bb",
   "metadata": {},
   "source": [
    "All scores are relatively high, with Recall being the highest at 0.8016 and Precision being the lowest at 0.7731, which is indicative that the model predicted more false positives than false negatives.<br>\n",
    "f1 score outperforms that of baseline, and KNN, RandomForest and Logistic Regression with hyperparameter tuning, but is slighlty worse than MNB with hyperparameter tuning.\n",
    "\n",
    "**Summary of the test scores for the Support Vector Machine Model with hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "117e6878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric        Score\n",
      "---------  --------\n",
      "Accuracy   0.7804\n",
      "Recall     0.7784\n",
      "Precision  0.781526\n",
      "f1 Score   0.77996\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Metric', 'Score'],\n",
    "                ['Accuracy', gs_svm.score(X_test, y_test)],\n",
    "               ['Recall', recall_score(y_test, gs_svm.predict(X_test))],\n",
    "               ['Precision', precision_score(y_test, gs_svm.predict(X_test))],\n",
    "               ['f1 Score', f1_score(y_test, gs_svm.predict(X_test))]],\n",
    "               headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4c142a",
   "metadata": {},
   "source": [
    "## Summary of modelling scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "116837fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                      Accuracy    Recall    Precision    f1 Score\n",
      "-----------------------  ----------  --------  -----------  ----------\n",
      "Baseline                     0.58      0.5688     0.581833    0.575243\n",
      "k-Nearest Neighbors          0.6048    0.6952     0.588753    0.637564\n",
      "Random Forest                0.7496    0.7128     0.76943     0.740033\n",
      "Multinomial Naive Bayes      0.7908    0.8184     0.775588    0.796419\n",
      "Logistic Regression          0.7852    0.78       0.788197    0.784077\n",
      "Support Vector Machine       0.7804    0.7784     0.781526    0.77996\n",
      "\n",
      "The Baseline model being k-Nearest Neighbors without any hyperparameter tuning.\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['Model', 'Accuracy', 'Recall', 'Precision', 'f1 Score'],\n",
    "                ['Baseline', pipe_knn_base.score(X_test, y_test), recall_score(y_test, pipe_knn_base.predict(X_test)), precision_score(y_test, pipe_knn_base.predict(X_test)), f1_score(y_test, pipe_knn_base.predict(X_test))],\n",
    "               ['k-Nearest Neighbors', gs_knn.score(X_test, y_test), recall_score(y_test, gs_knn.predict(X_test)), precision_score(y_test, gs_knn.predict(X_test)), f1_score(y_test, gs_knn.predict(X_test))],\n",
    "               ['Random Forest', gs_rf.score(X_test, y_test), recall_score(y_test, gs_rf.predict(X_test)), precision_score(y_test, gs_rf.predict(X_test)), f1_score(y_test, gs_rf.predict(X_test))],\n",
    "               ['Multinomial Naive Bayes', gs_nb.score(X_test, y_test), recall_score(y_test, gs_nb.predict(X_test)), precision_score(y_test, gs_nb.predict(X_test)), f1_score(y_test, gs_nb.predict(X_test))],\n",
    "               ['Logistic Regression', gs_log.score(X_test, y_test), recall_score(y_test, gs_log.predict(X_test)), precision_score(y_test, gs_log.predict(X_test)), f1_score(y_test, gs_log.predict(X_test))],\n",
    "               ['Support Vector Machine', gs_svm.score(X_test, y_test), recall_score(y_test, gs_svm.predict(X_test)), precision_score(y_test, gs_svm.predict(X_test)), f1_score(y_test, gs_svm.predict(X_test))]],\n",
    "               headers='firstrow'))\n",
    "\n",
    "print('') # leave a space\n",
    "\n",
    "print('The Baseline model being k-Nearest Neighbors without any hyperparameter tuning.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb42964",
   "metadata": {},
   "source": [
    "All models showed overfitting based on the train and test accuracy score.\n",
    "\n",
    "For all models with hyperparameter tuning, there was no removal of stopwords - this makes sense, as most models had ngram ranges of (1, 2). Bi-grams tend to not make as much sense with stopwords removed.\n",
    "\n",
    "As can be seen from the table above, recall is always lower than precision for all models except Multinomial Naive Bayes and the baseline. This indicates that the models tend to predict more false negatives than false positives for this dataset.\n",
    "\n",
    "The baseline(KNN with no hyperparameter tuning) has the worst overall performance, with every other model outperforming it in all chosen metrics.\n",
    "\n",
    "Multinomial Naive Bayes has the best accuracy, recall, precision and f1 score, f1 score being the most important metric in this project. \n",
    "\n",
    "As Multinomial Naive Bayes has the highest number of best metrics, especially the f1 score, it will thus serve as our reccomended model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917eb43a",
   "metadata": {},
   "source": [
    "### Visually Evaluating the Recommended Multinomial Naive Bayes Model Using ROC Curve\n",
    "The ROC curve provides a good visualisation on how well the model performs.\n",
    "\n",
    "Plot the True Positive Rate (**sensitivity**) vs. False Positive Rate (**1 - specificity**) for the range of possible decision thresholds (from 0 to 1) will give you the ROC curve.\n",
    "\n",
    "$$\\text{True Positive Rate (TPR/Sensitivity/Recall)} = \\frac{TP}{P} = \\frac{TP}{TP+FN}$$\n",
    "$$\\text{True Negative Rate (TNR/Specificity)} = \\frac{TN}{N} = \\frac{TN}{TN+FP}$$\n",
    "$$\\text{False Positive Rate (FPR)} = \\frac{FP}{N} = \\frac{FP}{FP+TN} = \\text{1 - TNR}$$ \n",
    "\n",
    "We will first recreate the Multinomial Naive Bayes Model(MNB) model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16f8f03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.8,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': None,\n",
       " 'nb__alpha': 1.6142857142857143,\n",
       " 'nb__fit_prior': True}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recap on MNB best params\n",
    "gs_nb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8bd6335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline with the best parameters\n",
    "best_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer(max_df=0.8, max_features=None, min_df=1, # instantiate CountVectorizer\n",
    "                             ngram_range=(1,2), stop_words=None)),\n",
    "    ('mnb', MultinomialNB(alpha=1.6142857142857143, fit_prior=True)) # instantiate MNB\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bff7ee98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB test ACCURACY: 0.7908\n",
      "MNB test RECALL: 0.8184\n",
      "MNB test PRECISION: 0.775587566338135\n",
      "MNB test f1 SCORE: 0.7964188400155703\n"
     ]
    }
   ],
   "source": [
    "best_nb_model = best_nb.fit(X_train, y_train)\n",
    "best_nb_preds = best_nb_model.predict(X_test)\n",
    "print(f'MNB test ACCURACY: {best_nb_model.score(X_test, y_test)}')\n",
    "print(f'MNB test RECALL: {recall_score(y_test, best_nb_preds)}')\n",
    "print(f'MNB test PRECISION: {precision_score(y_test, best_nb_preds)}')\n",
    "print(f'MNB test f1 SCORE: {f1_score(y_test, best_nb_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e588da",
   "metadata": {},
   "source": [
    "The metrics of the recreated MNB model match that of the hyperparamter tuned model. We can now proceed to plot the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c24df123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(best_nb, X_test, y_test)\n",
    "plt.plot([0, 1], [0, 1],\n",
    "         label='baseline', linestyle='--') # to simulate random guess \n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e85c9",
   "metadata": {},
   "source": [
    "For a typical ROC curve, if AUC is **0.5**, the positive and negative populations overlap perfectly, and the model is as bad as can get, which is represented by the baseline. If the AUC is **1**, the positive and negative populations are perfectly separated, thus showing that the model is as good as it can get.\n",
    "\n",
    "The ROC plot for the reccomended MNB model shows a fairly smooth curve with an AUC of **0.88** the model is a 88% chance that the model can distinguish between a post from TheOnion and nottheonion.\n",
    "\n",
    "The optimal classification threshold is around 0.8, where we can maximise the true positives while keeping false positive rate at a manageable level. \n",
    "\n",
    "Lastly, this AUC of **0.88** which is relatively close to the maximum score of **1.0**. We can thus conclude that this model performs well!\n",
    "\n",
    "An AUC between 0.8 - 0.9 is generally considered as 'excellent'<sup>2</sup> in the industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a3685",
   "metadata": {},
   "source": [
    "### True Positives vs False Positives & True Negatives vs False Negatives in recommended MNB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78b8af10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preds\n",
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      1\n",
       "4      1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nb = best_nb.predict(X_test)\n",
    "pred_nb_df = pd.DataFrame(pred_nb, columns=['preds']) # convert to dataframe for easy concatication\n",
    "pred_nb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c8096338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives:954\n",
      "False Positives:296\n",
      "False Negatives:227\n",
      "True Positives:1023\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred_nb).ravel()\n",
    "print(f'True Negatives:{tn}\\nFalse Positives:{fp}\\nFalse Negatives:{fn}\\nTrue Positives:{tp}')\n",
    "\n",
    "# plot confusion matrix\n",
    "plot_confusion_matrix(best_nb, X_test, y_test, cmap='Greens', values_format='d');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee031ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_text</th>\n",
       "      <th>onion</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why liberal white woman pay a lot of money to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>goose thinking of migrating home a couple week...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hitman hire hitman who hire hitman who hire hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 amber alert that were sent out that were cle...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sequel to original ghostbusters being made</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            new_text  onion  preds\n",
       "0  why liberal white woman pay a lot of money to ...      0      1\n",
       "1  goose thinking of migrating home a couple week...      1      1\n",
       "2  hitman hire hitman who hire hitman who hire hi...      0      0\n",
       "3  5 amber alert that were sent out that were cle...      1      1\n",
       "4         sequel to original ghostbusters being made      1      1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatinate the X_test and the predictions\n",
    "pred_vs_actual_nb = pd.concat([pd.DataFrame(X_test).reset_index(drop=True), pd.DataFrame(y_test).reset_index(drop=True), pred_nb_df], axis=1)\n",
    "print(pred_vs_actual_nb.shape)\n",
    "pred_vs_actual_nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3985e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_text</th>\n",
       "      <th>onion</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>goose thinking of migrating home a couple week...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 amber alert that were sent out that were cle...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sequel to original ghostbusters being made</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dishwasher think he s mentoring younger dishwa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>new york time announces new columnist will con...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             new_text  onion  preds\n",
       "1   goose thinking of migrating home a couple week...      1      1\n",
       "3   5 amber alert that were sent out that were cle...      1      1\n",
       "4          sequel to original ghostbusters being made      1      1\n",
       "10  dishwasher think he s mentoring younger dishwa...      1      1\n",
       "13  new york time announces new columnist will con...      1      1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the true positives\n",
    "# true positives are 1 in both onion and preds column\n",
    "true_positive_nb = pred_vs_actual_nb[(pred_vs_actual_nb.onion==1)&(pred_vs_actual_nb.preds==1)]\n",
    "print(true_positive_nb.shape)\n",
    "true_positive_nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68511358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(954, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_text</th>\n",
       "      <th>onion</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hitman hire hitman who hire hitman who hire hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the dea may have botched a cartel case over sl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hangover cure the only way to avoid suffering ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>billionaire investor bill gross ordered to sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lady gaga offer 500 000 for return of dog afte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            new_text  onion  preds\n",
       "2  hitman hire hitman who hire hitman who hire hi...      0      0\n",
       "5  the dea may have botched a cartel case over sl...      0      0\n",
       "6  hangover cure the only way to avoid suffering ...      0      0\n",
       "7  billionaire investor bill gross ordered to sto...      0      0\n",
       "8  lady gaga offer 500 000 for return of dog afte...      0      0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the true negatives\n",
    "# true negatives are 0 in both onion and preds column\n",
    "true_negative_nb = pred_vs_actual_nb[(pred_vs_actual_nb.onion==0)&(pred_vs_actual_nb.preds==0)]\n",
    "print(true_negative_nb.shape)\n",
    "true_negative_nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "af8c7853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_text</th>\n",
       "      <th>onion</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why liberal white woman pay a lot of money to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sadly marine are probably never going to space</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>amazon worker are listening to what you tell a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>column larry elder is the black face of white ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>senate peg tenure of igp to 4 year single term...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             new_text  onion  preds\n",
       "0   why liberal white woman pay a lot of money to ...      0      1\n",
       "9      sadly marine are probably never going to space      0      1\n",
       "15  amazon worker are listening to what you tell a...      0      1\n",
       "23  column larry elder is the black face of white ...      0      1\n",
       "33  senate peg tenure of igp to 4 year single term...      0      1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the false positives\n",
    "# false positives are 1 in onion and 0 in preds column\n",
    "false_positive_nb = pred_vs_actual_nb[(pred_vs_actual_nb.onion==0)&(pred_vs_actual_nb.preds==1)]\n",
    "print(false_positive_nb.shape)\n",
    "false_positive_nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2843259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_text</th>\n",
       "      <th>onion</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>death penalty for spitting on shopping trolley...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>belarus s lukashenko meet opposition in kgb ja...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>woman jealous of horse s eyelash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>justin trudeau explains deep spiritual signifi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>delhi minister seek cancellation of singapore ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             new_text  onion  preds\n",
       "12  death penalty for spitting on shopping trolley...      1      0\n",
       "36  belarus s lukashenko meet opposition in kgb ja...      1      0\n",
       "41                   woman jealous of horse s eyelash      1      0\n",
       "51  justin trudeau explains deep spiritual signifi...      1      0\n",
       "56  delhi minister seek cancellation of singapore ...      1      0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the false negatives\n",
    "# false negatives are 0 in onion and 1 in preds column\n",
    "false_negative_nb = pred_vs_actual_nb[(pred_vs_actual_nb.onion==1)&(pred_vs_actual_nb.preds==0)]\n",
    "print(false_negative_nb.shape)\n",
    "false_negative_nb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa0f30",
   "metadata": {},
   "source": [
    "To find out why false positives were classifed wrongly, we will look at their top 10 words by frequency and compare it with the top 10 words of the true positives.\n",
    "\n",
    "Similarly, to find out why false negatives were classifed wrongly, we will look at their top 10 words by frequency and compare it with the top 10 words of the true negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f721b59",
   "metadata": {},
   "source": [
    "#### Comparison of Top 10 Words in True Positives and False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "640a168e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to', 'of', 'the', 'in', 'for', 'on', 'with', 'and', 'it', 'this']\n"
     ]
    }
   ],
   "source": [
    "# what are top words in true positive?\n",
    "tp_words = [x for x in dict(pd.DataFrame(best_nb['cvec'].transform(true_positive_nb.new_text).toarray(),\n",
    "             columns=best_nb['cvec'].get_feature_names()).sum().sort_values(ascending=False).head(10))]\n",
    "print(tp_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a8b8a42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to', 'the', 'of', 'in', 'for', 'and', 'is', 'on', 'with', 'that']\n"
     ]
    }
   ],
   "source": [
    "# what are top words in false positive?\n",
    "fp_words = [x for x in dict(pd.DataFrame(best_nb['cvec'].transform(false_positive_nb.new_text).toarray(),\n",
    "             columns=best_nb['cvec'].get_feature_names()).sum().sort_values(ascending=False).head(10))]\n",
    "print(fp_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e90527b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to', 'the', 'of', 'in', 'for', 'and', 'on', 'with']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are common top words in true positive and false positive?\n",
    "positive_words = [x for x in fp_words if x in tp_words]\n",
    "positive_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d52b6fe",
   "metadata": {},
   "source": [
    "Most of these words are stopwords like 'to', 'in', 'of' etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef344eb",
   "metadata": {},
   "source": [
    "#### Comparison of True Negatives and False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "387f1f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to', 'in', 'for', 'of', 'the', 'after', 'man', 'on', 'and', 'say']\n"
     ]
    }
   ],
   "source": [
    "# what are top words in true negative?\n",
    "tn_words = [x for x in dict(pd.DataFrame(best_nb['cvec'].transform(true_negative_nb.new_text).toarray(),\n",
    "             columns=best_nb['cvec'].get_feature_names()).sum().sort_values(ascending=False).head(10))]\n",
    "print(tn_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f0603d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to', 'of', 'in', 'for', 'on', 'the', 'with', 'trump', 'from', 'after']\n"
     ]
    }
   ],
   "source": [
    "# what are top words in false negative?\n",
    "fn_words = [x for x in dict(pd.DataFrame(best_nb['cvec'].transform(false_negative_nb.new_text).toarray(),\n",
    "             columns=best_nb['cvec'].get_feature_names()).sum().sort_values(ascending=False).head(10))]\n",
    "print(fn_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2bd3e981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to', 'of', 'in', 'for', 'on', 'the', 'after']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are common top words in true negative and false negative?\n",
    "negative_words = [x for x in fn_words if x in tn_words]\n",
    "negative_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d277331",
   "metadata": {},
   "source": [
    "Similar to the true vs false positives above, most of these words are stop words.<br>\n",
    "In conclusion, not much meaning can be derived from just looking at the common top words, as most, if not all, happen to be stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12abfebb",
   "metadata": {},
   "source": [
    "#### Coefficient Intepretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8174ee63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.3058734 ,  -8.26656882, -10.98197007, ..., -11.3058734 ,\n",
       "       -11.78797174, -11.78797174])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nottheonion_importance = best_nb_model['mnb'].feature_log_prob_[0, :]\n",
    "nottheonion_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7aee6740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.81310773,  -8.42886747, -11.3310094 , ..., -11.81310773,\n",
       "       -11.3310094 , -11.3310094 ])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_importance = best_nb_model['mnb'].feature_log_prob_[1, :]\n",
    "onion_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ccf19149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77525, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>-11.305873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>-8.266569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000 000</th>\n",
       "      <td>-10.981970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000 action</th>\n",
       "      <td>-11.305873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000 after</th>\n",
       "      <td>-10.737707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            coefficients\n",
       "00            -11.305873\n",
       "000            -8.266569\n",
       "000 000       -10.981970\n",
       "000 action    -11.305873\n",
       "000 after     -10.737707"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_nottheonion = pd.DataFrame(data=nottheonion_importance, columns=['coefficients'],\n",
    "                                       index=best_nb_model['cvec'].get_feature_names())\n",
    "print(df_features_nottheonion.shape)\n",
    "df_features_nottheonion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a85ac708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>-4.979568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>-5.522082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-5.619676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-5.658035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>-5.775209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>-6.169657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>-6.227528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>after</th>\n",
       "      <td>-6.319837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>-6.381832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>-6.465912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coefficients\n",
       "to        -4.979568\n",
       "in        -5.522082\n",
       "of        -5.619676\n",
       "the       -5.658035\n",
       "for       -5.775209\n",
       "on        -6.169657\n",
       "and       -6.227528\n",
       "after     -6.319837\n",
       "with      -6.381832\n",
       "man       -6.465912"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_nottheonion.sort_values(by='coefficients', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1497ee",
   "metadata": {},
   "source": [
    "Most of the words that predict nottheonion well are stop words, save for 'man'. Thus not much meaning can be derived from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b36ed9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77525, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>-11.813108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>-8.428867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000 000</th>\n",
       "      <td>-11.331009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000 action</th>\n",
       "      <td>-11.813108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000 after</th>\n",
       "      <td>-11.813108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            coefficients\n",
       "00            -11.813108\n",
       "000            -8.428867\n",
       "000 000       -11.331009\n",
       "000 action    -11.813108\n",
       "000 after     -11.813108"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_theonion = pd.DataFrame(data=onion_importance, columns=['coefficients'],\n",
    "                                       index=best_nb_model['cvec'].get_feature_names())\n",
    "print(df_features_theonion.shape)\n",
    "df_features_theonion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4463ede9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>-4.863896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-5.267695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-5.644812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>-5.723060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>-5.954088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>-6.309036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>-6.485017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>-6.500163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>-6.669376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>-6.672998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      coefficients\n",
       "to       -4.863896\n",
       "of       -5.267695\n",
       "the      -5.644812\n",
       "in       -5.723060\n",
       "for      -5.954088\n",
       "on       -6.309036\n",
       "and      -6.485017\n",
       "with     -6.500163\n",
       "new      -6.669376\n",
       "by       -6.672998"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_theonion.sort_values(by='coefficients', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e53de99",
   "metadata": {},
   "source": [
    "Similar to the coefficients above, most of the words that predict nottheonion well are stop words, save for 'new'. Thus not much meaning can be derived from this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624db62",
   "metadata": {},
   "source": [
    "In conclusion, not much meaning can be derived from just looking at the common top words, as most, if not all, happen to be stopwords. This shows the extent of the 'blackboxness' of MNB, and why we still need to look at logistic regression for intepretability.\n",
    "\n",
    "We can use the interpretability of the logistic regression model to study coefficients of the various features and see which words had the strongest impact on classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8113a4f7",
   "metadata": {},
   "source": [
    "### Logistic Regression Coefficients\n",
    "\n",
    "To study the coefficients, we will need to recreate the Logistic Regression model with the best parameters.\n",
    "\n",
    "A quick recap on the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "77f46861",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.8,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': None,\n",
       " 'log__max_iter': 100,\n",
       " 'log__penalty': 'l2',\n",
       " 'log__random_state': 42}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_log.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "083b7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the TfidfVectorizer with best parameters\n",
    "cvec_log = CountVectorizer(max_df=0.8, max_features=None, min_df=1, ngram_range=(1,2), stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a7361b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform the training data and trainsform the test data\n",
    "Z_train = cvec_log.fit_transform(X_train)\n",
    "Z_test = cvec_log.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fc332c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the LogisticRegression with best parameters\n",
    "log_best = LogisticRegression(max_iter=100, random_state=42, penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "14f67b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 0.9997333333333334\n",
      "Test accuracy is 0.7852\n"
     ]
    }
   ],
   "source": [
    "# fit the train data, and get the accuracy scores\n",
    "log_best.fit(Z_train, y_train)\n",
    "print(f'Train accuracy is {log_best.score(Z_train, y_train)}')\n",
    "print(f'Test accuracy is {log_best.score(Z_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a26c25e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression test RECALL: 0.78\n",
      "LogisticRegression test PRECISION: 0.788197251414713\n",
      "LogisticRegression test f1 SCORE: 0.7840772014475271\n"
     ]
    }
   ],
   "source": [
    "# get the other metrics\n",
    "print(f'LogisticRegression test RECALL: {recall_score(y_test, log_best.predict(Z_test))}')\n",
    "print(f'LogisticRegression test PRECISION: {precision_score(y_test, log_best.predict(Z_test))}')\n",
    "print(f'LogisticRegression test f1 SCORE: {f1_score(y_test, log_best.predict(Z_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9ddef",
   "metadata": {},
   "source": [
    "The metrics for recreated Logistic Regression model match that of the hyperparamter tuned model. We can now start interpretating the coefficients.\n",
    "\n",
    "The coefficents of the Logistic Regression are the Log(Odds Ratio)<sup>3</sup> of determining the positive class (TheOnion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3acdd4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating index of feature names\n",
    "index_log = cvec_log.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a1434238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a dataframe of feature names and their respective coefficients\n",
    "log_coef_df = pd.DataFrame(log_best.coef_[0],\n",
    "                         columns=[\"coefficient\"],\n",
    "                         index=index_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7f1eecdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>said what</th>\n",
       "      <td>1.566929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nation</th>\n",
       "      <td>1.549186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>1.547807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announces</th>\n",
       "      <td>1.432677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shit</th>\n",
       "      <td>1.380316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>1.370246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congress</th>\n",
       "      <td>1.303354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fucking</th>\n",
       "      <td>1.278267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self</th>\n",
       "      <td>1.227514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>1.218810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coefficient\n",
       "said what     1.566929\n",
       "nation        1.549186\n",
       "way           1.547807\n",
       "announces     1.432677\n",
       "shit          1.380316\n",
       "all           1.370246\n",
       "congress      1.303354\n",
       "fucking       1.278267\n",
       "self          1.227514\n",
       "this          1.218810"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 words/ngrams\n",
    "\n",
    "log_coef_df.sort_values(by='coefficient', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "af49e65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>say he</th>\n",
       "      <td>-1.240334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this is</th>\n",
       "      <td>-1.248961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accused</th>\n",
       "      <td>-1.261092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>florida</th>\n",
       "      <td>-1.262506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snake</th>\n",
       "      <td>-1.284463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken</th>\n",
       "      <td>-1.286658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>-1.315480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>-1.324158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toilet</th>\n",
       "      <td>-1.358766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police</th>\n",
       "      <td>-1.405872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefficient\n",
       "say he     -1.240334\n",
       "this is    -1.248961\n",
       "accused    -1.261092\n",
       "florida    -1.262506\n",
       "snake      -1.284463\n",
       "chicken    -1.286658\n",
       "uk         -1.315480\n",
       "are        -1.324158\n",
       "toilet     -1.358766\n",
       "police     -1.405872"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bottom 5 words/ngrams\n",
    "log_coef_df.sort_values(by='coefficient', ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6db25d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>said what</th>\n",
       "      <td>1.566929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nation</th>\n",
       "      <td>1.549186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>1.547807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announces</th>\n",
       "      <td>1.432677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shit</th>\n",
       "      <td>1.380316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>1.370246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congress</th>\n",
       "      <td>1.303354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fucking</th>\n",
       "      <td>1.278267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self</th>\n",
       "      <td>1.227514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>1.218810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say he</th>\n",
       "      <td>-1.240334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this is</th>\n",
       "      <td>-1.248961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accused</th>\n",
       "      <td>-1.261092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>florida</th>\n",
       "      <td>-1.262506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snake</th>\n",
       "      <td>-1.284463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken</th>\n",
       "      <td>-1.286658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>-1.315480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>-1.324158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toilet</th>\n",
       "      <td>-1.358766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police</th>\n",
       "      <td>-1.405872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coefficient\n",
       "said what     1.566929\n",
       "nation        1.549186\n",
       "way           1.547807\n",
       "announces     1.432677\n",
       "shit          1.380316\n",
       "all           1.370246\n",
       "congress      1.303354\n",
       "fucking       1.278267\n",
       "self          1.227514\n",
       "this          1.218810\n",
       "say he       -1.240334\n",
       "this is      -1.248961\n",
       "accused      -1.261092\n",
       "florida      -1.262506\n",
       "snake        -1.284463\n",
       "chicken      -1.286658\n",
       "uk           -1.315480\n",
       "are          -1.324158\n",
       "toilet       -1.358766\n",
       "police       -1.405872"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_coef_df = pd.concat([log_coef_df.sort_values(by='coefficient', ascending=False).head(10),\n",
    "                           log_coef_df.sort_values(by='coefficient', ascending=False).tail(10)],\n",
    "                       axis=0)\n",
    "top_coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "601e1ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting most significant coefs\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.barplot(data=top_coef_df,\n",
    "            x=\"coefficient\",\n",
    "            y=top_coef_df.index,\n",
    "            palette=\"seismic\")\n",
    "plt.title(\"Top Words/ngrams for Determining TheOnion Post\", size=15)\n",
    "plt.yticks(size=10)\n",
    "plt.xticks(size=10)\n",
    "plt.ylabel(\"Words/ngrams\", size=16)\n",
    "plt.xlabel(\"Model Coefficient\\nLog(Odds Ratio) of Being from TheOnion\", size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e414b",
   "metadata": {},
   "source": [
    "#### Strong predictors of TheOnion (Fake News)\n",
    "From the graph, we can see that key words like 'nation', 'announces', 'shit' , 'congress' and 'fucking' are strong indicators that a headline is from TheOnion, our fake news dataset.<br>\n",
    "These words are not stopwords, and provide a clearer picture on the anatomy of TheOnion, ie fake news headline:\n",
    "- Profanities such as 'shit' and 'fucking' are indicators that the news is fake, as creators of fake news have lesser restrictions on the language used in their headlines. To draw sentiment and capture the attention of the reader, such profanities may be used.\n",
    "- The word 'announces' and 'congress' very likely go hand in hand in many fake news articles, as whenever 'congress or governments announces something', it will catch the attention of the reader. Fake news creators likely know this, and thus use it to their advantage.\n",
    "- The word 'nation' also is a strong predictor. Anything that affects the 'nation' is bound to draw attention, and thus fake news creators may use this word often.\n",
    "- An interesting one is the bigram 'said what'. These two words when used together with someone famous, conjures up feelings of controversy. For example 'Joe Biden Said What!' is a very eye catching headline that will garner more readership, and can be used by fake news creators. Such headlines are also a signature of tabloids, and thus will be rare in a real news headline.\n",
    "\n",
    "#### Weak predictors of TheOnion (Fake News)\n",
    "From the graph, we can see that key words like 'police', 'toilet', 'uk', 'chicken' , 'snake', 'florida' and 'accused' are weak indicators that a headline is from TheOnion, our fake news dataset.<br>\n",
    "- The word 'Police' is a weak indicator, possibly because there are numerous real news articles invloving the police on a daily basis, on a variety of cases. Fake news creators may have a hard time keeping up in creating false scenarios invloving the police, who may be invloved in extreme and sometimes ridiculous cases quite frequently!\n",
    "- The word 'uk' is a confusing one. It is likely to be the United Kingdom. Perhaps they are the most trustworthy country on earth? I am unable to draw any conclusions from this one.\n",
    "- The words 'toilet and 'Florida' are noteworthy. There are many sensational incidents that happen in these 2 very different locations. Florida for example, has a whole fanbase based off the infamous 'Florida Man'<sup>4</sup> and his exploits. Fake news creators may not be able to create news as sensational as news involving toilets or Florida.\n",
    "- The words 'snake' and 'chicken' are that of animals. If an animal ends up in the news, the scenario is probably sensational already, thus not as much value can be placed on a fake news article involving animals. Also, if the intention of fake news is to incite panic or cause harm, animals may not be the most efficient way to do so.\n",
    "- The word 'accused' and the law have many things in common. In daily news, there are many articles of various individuals being 'accused' of 'multitude' of offenses. Similar to the 'police', fake news creators may have a hard time keeping up with new accusations happening on a frequent basis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5d80c",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "We set out to create a model that was discerning enough to separate fake news from real news as well as being simple to use, and also minimize false positives and false negatives.\n",
    "\n",
    "By choosing the Multinomial Naive Bayes(MNB) model as the recommended model, we are able to achieve good metrics, with a f1 score of **0.796419**, showing that this MNB model did in fact minimize the false positives and false negatives.<br>\n",
    "This was further backed up by the ROC curve of the MNB model showing a an AUC of **0.88**, which is close to the maximum possible AUC of **1**. This model thus fulfils the 'minimize false positives and false negatives' criteria.<br>\n",
    "Since the model is MNB, it is not very intepretableand thus is perfect for the general public, who just want to key in the news headline and get an answer whether it is likely to be fake news or not. It will also be easy to develop this model into an app, as the number of features required will be lesser.<br>\n",
    "One good use case would be - a working class adult can easily caution to his/her elderly parents about a particular news being potentially fake, because \"the government app said so\".\n",
    "\n",
    "However, should one require a model with greater intepretability, then Logistic Regression should be chosen. This model also performed well on our dataset, with metrics close to that of the MNB model.<br>\n",
    "Government bodies such as the police can use the intepretability of the model to educate members of the public on how to spot potential fake news.<br>\n",
    "For example, the public can be warned that news that sounds very tabliod-ish, or uses profanities have a higher chance of being fake. Another example would be that if a news source seemingly 'quotes' governments or people of influence such a CEO, memebers of the public can be advised to substantiate this information with news from reputable, official sources, such as The Straits Times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c6cea3",
   "metadata": {},
   "source": [
    "# Recommendations for Improvement\n",
    "\n",
    "Despite the chosen Multinomial Naive Bayes(MNB) performing well, it was still overfit nonetheless. The limitation here is that the models used were considered relatively more simple. More advanced techniques, such as using TENSORFLOW and BERT, could be used in the future to generate models with strong metrics, as well as reduced overfitting.\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a state of the art model developed by Google. As opposed to directional models, which read the text input sequentially (left-to-right or right-to-left), the Transformer encoder reads the entire sequence of words at once. Therefore it is considered bidirectional, though it would be more accurate to say that it’s non-directional. This characteristic allows the model to learn the context of a word based on all of its surroundings (left and right of the word).<sup>5</sup>\n",
    "\n",
    "Another limitation of the chosen MNB model is that it can only predict English headlines. In a multi-racial society such as Singapore, fake news can come in many languages. This can be especially dangerous to elderly folk, who mostly converse in their mother tongue. Further study and development of the model to accept other languages can be explored.\n",
    "\n",
    "Lastly, the datasets were pulled from sometime between end 2018 to end 2021, a 3 year time span. The hot topics may change over the course of 2022 and beyond, so this model needs to be constantly re-trained on the most updated news topics for it to stay relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496822d",
   "metadata": {},
   "source": [
    "# References\n",
    "1. https://www.analyticsvidhya.com/blog/2020/11/a-tour-of-evaluation-metrics-for-machine-learning/\n",
    "2. https://www.statology.org/what-is-a-good-auc-score/\n",
    "3. https://quantifyinghealth.com/interpret-logistic-regression-coefficients/\n",
    "4. https://www.reddit.com/r/FloridaMan/\n",
    "5. https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eddb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
